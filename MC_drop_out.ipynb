{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.distributions import Bernoulli\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ed7aceb9359c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Training X shape: (60000, 784)\n",
      "Testing X shape: (9000, 784)\n",
      "Validation X shape: (1000, 784)\n",
      "\n",
      "Training Y shape: (60000, 10)\n",
      "Testing Y shape: (9000, 10)\n",
      "Validation Y shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data/mnist', validation_size=0, one_hot=True)\n",
    "test_len = mnist.test.images.shape[0]\n",
    "validation_len = int(test_len * 0.1)\n",
    "num_label=10\n",
    "train_x = mnist.train.images\n",
    "test_x = mnist.test.images[validation_len : test_len, :]\n",
    "validation_x = mnist.test.images[ : validation_len, :]\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels[validation_len : test_len]\n",
    "validation_y = mnist.test.labels[ : validation_len]\n",
    "\n",
    "print(\"\\nTraining X shape: \" + str(train_x.shape))\n",
    "print(\"Testing X shape: \" + str(test_x.shape))\n",
    "print(\"Validation X shape: \" + str(validation_x.shape))\n",
    "\n",
    "print(\"\\nTraining Y shape: \" + str(train_y.shape))\n",
    "print(\"Testing Y shape: \" + str(test_y.shape))\n",
    "print(\"Validation Y shape: \" + str(validation_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(safe_images[0].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/senqicao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import scipy.misc as scimisc\n",
    "safe_list = [0,2,5,6,8,12,13,14,15,16,17,18,19,21,26]  # other alphabets have characters which look like digits\n",
    "m = sio.loadmat(\"./data/data_background.mat\")\n",
    "\n",
    "squished_set = []\n",
    "for safe_number in safe_list:\n",
    "    for alphabet in m['images'][safe_number]:\n",
    "        for letters in alphabet:\n",
    "            for letter in letters:\n",
    "                for example in letter:\n",
    "                    squished_set.append(scimisc.imresize(1 - example[0], (28,28)).reshape(1, 28*28))\n",
    "\n",
    "safe_images = np.concatenate(squished_set, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_x\n",
    "y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Created sample data.\n",
    "n_samples = 200\n",
    "X = np.random.normal(size=(n_samples, 1))\n",
    "y = np.random.normal(np.cos(5.*X) / (np.abs(X) + .1), .5).ravel()\n",
    "#y = np.random.normal(5.*X, 3.5).ravel()\n",
    "X_pred = np.atleast_2d(np.linspace(-4., 4., num=50)).T\n",
    "X = np.hstack((X, X**2, X**3))\n",
    "X_pred = np.hstack((X_pred, X_pred**2, X_pred**3))\n",
    "plt.plot(X[:, 0], y, \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./MC_dropout/classification_mnist12/model.ckpt\n",
      "time 600 503.9454047679901 test accuracy:  0.9837 0.9793\n",
      "maxp_OOD: 0.021195652173913043 0.6217482024530907 0.2088420347457005\n",
      "maxp_inD: 0.6169 0.9604826731524742 0.09373436077218197\n",
      "ent_OOD: 1.0406515972322892 0.4816863760189323 ent_in: 0.14055064062609224 0.2463902994169574\n",
      "MI_OOD: 0.10866152846789026 0.060444636223329594 ent_in: 0.012826150470851545 0.026415776450768154\n",
      "AUPR_p: 93.45\n",
      "AUROC_p: 94.53\n",
      "AUPR_entropy: 94.34\n",
      "AUROC_entropy: 94.99\n",
      "AUPR_MI: 93.53\n",
      "AUROC_MI: 94.57\n",
      "############################################\n",
      "time 1200 1213.2813439369202 test accuracy:  0.9897 0.9862\n",
      "maxp_OOD: 0.012826086956521739 0.6008363406160101 0.20707313683581385\n",
      "maxp_inD: 0.6642 0.969439739526647 0.08094699656238012\n",
      "ent_OOD: 1.1077698401790512 0.4759453194609991 ent_in: 0.1177584797933358 0.21875654405665193\n",
      "MI_OOD: 0.09182069184759563 0.04922001330350152 ent_in: 0.00781455277820576 0.017590204562634337\n",
      "AUPR_p: 95.63\n",
      "AUROC_p: 96.44\n",
      "AUPR_entropy: 96.25\n",
      "AUROC_entropy: 96.76\n",
      "AUPR_MI: 96.0\n",
      "AUROC_MI: 96.59\n",
      "############################################\n",
      "time 1800 1927.6906728744507 test accuracy:  0.9891 0.9886\n",
      "maxp_OOD: 0.015 0.6031820363691683 0.21133564491619192\n",
      "maxp_inD: 0.6566 0.9680901921172068 0.08254286954525501\n",
      "ent_OOD: 1.1136842395931243 0.4900026777151183 ent_in: 0.1203355541181922 0.2213062531904484\n",
      "MI_OOD: 0.07718830491120887 0.040784810108946724 ent_in: 0.008199785917002229 0.017599598774666273\n",
      "AUPR_p: 95.3\n",
      "AUROC_p: 96.07\n",
      "AUPR_entropy: 96.11\n",
      "AUROC_entropy: 96.52\n",
      "AUPR_MI: 94.51\n",
      "AUROC_MI: 95.62\n",
      "############################################\n",
      "time 2400 2646.5440368652344 test accuracy:  0.9898 0.9879\n",
      "maxp_OOD: 0.010326086956521738 0.6002234615213086 0.20604931048231648\n",
      "maxp_inD: 0.6694 0.9692381796761478 0.08137494188301753\n",
      "ent_OOD: 1.109926693010801 0.472771901516752 ent_in: 0.11801459392828667 0.22234368748424424\n",
      "MI_OOD: 0.07988508459120679 0.04195468275740757 ent_in: 0.007681308085029175 0.01692580963333458\n",
      "AUPR_p: 95.74\n",
      "AUROC_p: 96.57\n",
      "AUPR_entropy: 96.3\n",
      "AUROC_entropy: 96.86\n",
      "AUPR_MI: 95.34\n",
      "AUROC_MI: 96.27\n",
      "############################################\n",
      "time 3000 3363.368703842163 test accuracy:  0.9907 0.9884\n",
      "maxp_OOD: 0.011521739130434782 0.6014599117976107 0.20598228855896974\n",
      "maxp_inD: 0.6854 0.9713094446123393 0.07759210871842262\n",
      "ent_OOD: 1.109791647427252 0.47325759709395987 ent_in: 0.11152822636868875 0.21316662587816676\n",
      "MI_OOD: 0.09186286217522116 0.04792054038251978 ent_in: 0.007403458239425234 0.016942433687233718\n",
      "AUPR_p: 96.02\n",
      "AUROC_p: 96.73\n",
      "AUPR_entropy: 96.53\n",
      "AUROC_entropy: 97.02\n",
      "AUPR_MI: 96.37\n",
      "AUROC_MI: 96.98\n",
      "############################################\n",
      "time 3600 4093.660787820816 test accuracy:  0.9899 0.9887\n",
      "maxp_OOD: 0.012934782608695652 0.6047332436501933 0.2064638635188058\n",
      "maxp_inD: 0.691 0.9710557271255551 0.07982132549838894\n",
      "ent_OOD: 1.0916310968057719 0.4707867381398037 ent_in: 0.11062151594338207 0.21529779685631587\n",
      "MI_OOD: 0.09046129075414158 0.04860921957853289 ent_in: 0.0066916176398752 0.015391170846432023\n",
      "AUPR_p: 95.66\n",
      "AUROC_p: 96.55\n",
      "AUPR_entropy: 96.27\n",
      "AUROC_entropy: 96.85\n",
      "AUPR_MI: 96.69\n",
      "AUROC_MI: 97.09\n",
      "############################################\n",
      "time 4200 4769.827112913132 test accuracy:  0.9905 0.9873\n",
      "maxp_OOD: 0.009782608695652175 0.6029363439529594 0.2041192781988487\n",
      "maxp_inD: 0.6778 0.9708007650623904 0.0786565498908884\n",
      "ent_OOD: 1.0971423470181358 0.46571569735289714 ent_in: 0.11312104122266342 0.2138640987791446\n",
      "MI_OOD: 0.0762181601850847 0.04055322645858761 ent_in: 0.006673594759498337 0.015597550773975498\n",
      "AUPR_p: 95.95\n",
      "AUROC_p: 96.76\n",
      "AUPR_entropy: 96.49\n",
      "AUROC_entropy: 97.04\n",
      "AUPR_MI: 95.69\n",
      "AUROC_MI: 96.64\n",
      "############################################\n",
      "time 4800 5491.916501998901 test accuracy:  0.99 0.9903\n",
      "maxp_OOD: 0.012934782608695652 0.6104396558471356 0.20640056666736234\n",
      "maxp_inD: 0.6869 0.9722616158150386 0.075994204959234\n",
      "ent_OOD: 1.0738350006830566 0.4711764910361728 ent_in: 0.1075795264739058 0.20756477003614482\n",
      "MI_OOD: 0.09736084189767856 0.05188992429749012 ent_in: 0.006131501707119162 0.014053402920644104\n",
      "AUPR_p: 95.87\n",
      "AUROC_p: 96.59\n",
      "AUPR_entropy: 96.36\n",
      "AUROC_entropy: 96.85\n",
      "AUPR_MI: 97.46\n",
      "AUROC_MI: 97.65\n",
      "############################################\n",
      "time 5400 6273.9585609436035 test accuracy:  0.9909 0.9884\n",
      "maxp_OOD: 0.015108695652173912 0.6118611234595874 0.20765789437431872\n",
      "maxp_inD: 0.7073 0.9727349483362088 0.07742427213564751\n",
      "ent_OOD: 1.072182004235014 0.47587955423953227 ent_in: 0.1036121029318344 0.20826318075363012\n",
      "MI_OOD: 0.09299254556976863 0.05061371528414702 ent_in: 0.0070291953714047535 0.016844634621025645\n",
      "AUPR_p: 95.7\n",
      "AUROC_p: 96.49\n",
      "AUPR_entropy: 96.27\n",
      "AUROC_entropy: 96.79\n",
      "AUPR_MI: 96.32\n",
      "AUROC_MI: 96.86\n",
      "############################################\n",
      "time 6000 6973.375513792038 test accuracy:  0.991 0.9872\n",
      "maxp_OOD: 0.012717391304347826 0.6082732463136377 0.20620434738149362\n",
      "maxp_inD: 0.7069 0.9726126909781435 0.07669671328613352\n",
      "ent_OOD: 1.094483113815412 0.4741662067985761 ent_in: 0.10447583028661256 0.20765095729529306\n",
      "MI_OOD: 0.0897694237029126 0.04898481028144009 ent_in: 0.007152993359616899 0.016653318208704825\n",
      "AUPR_p: 95.96\n",
      "AUROC_p: 96.7\n",
      "AUPR_entropy: 96.59\n",
      "AUROC_entropy: 97.06\n",
      "AUPR_MI: 96.22\n",
      "AUROC_MI: 96.82\n",
      "############################################\n",
      "time 6600 7680.034976005554 test accuracy:  0.9915 0.9902\n",
      "maxp_OOD: 0.0125 0.6063075789771958 0.20622606642011101\n",
      "maxp_inD: 0.7109 0.9744658130912732 0.07311669188772607\n",
      "ent_OOD: 1.096201364222905 0.4747624016394964 ent_in: 0.10002230444525978 0.2000058561637003\n",
      "MI_OOD: 0.09342397983418838 0.04871129213586423 ent_in: 0.005998679245849205 0.01436564269139464\n",
      "AUPR_p: 96.28\n",
      "AUROC_p: 96.97\n",
      "AUPR_entropy: 96.81\n",
      "AUROC_entropy: 97.25\n",
      "AUPR_MI: 97.34\n",
      "AUROC_MI: 97.69\n",
      "############################################\n",
      "time 7200 8380.286156892776 test accuracy:  0.9914 0.99\n",
      "maxp_OOD: 0.012717391304347826 0.6116104634746005 0.20822619907382758\n",
      "maxp_inD: 0.6901 0.9722490152215585 0.07556118578282145\n",
      "ent_OOD: 1.087290600595417 0.4796178249145134 ent_in: 0.10822221128655515 0.2074306050640836\n",
      "MI_OOD: 0.08092412203425896 0.04472701376968165 ent_in: 0.0064565118388656886 0.01485468928822881\n",
      "AUPR_p: 95.88\n",
      "AUROC_p: 96.58\n",
      "AUPR_entropy: 96.45\n",
      "AUROC_entropy: 96.9\n",
      "AUPR_MI: 96.2\n",
      "AUROC_MI: 96.77\n",
      "############################################\n",
      "time 7800 9112.827136039734 test accuracy:  0.9917 0.989\n",
      "maxp_OOD: 0.014891304347826087 0.615492087376562 0.20715137270623693\n",
      "maxp_inD: 0.727 0.9748793743683151 0.07359548328216405\n",
      "ent_OOD: 1.0712880011659653 0.47752136165140846 ent_in: 0.0970676677864854 0.20009410689896337\n",
      "MI_OOD: 0.08490128686975484 0.045966553275879424 ent_in: 0.005173537620209961 0.013074290804011348\n",
      "AUPR_p: 95.97\n",
      "AUROC_p: 96.73\n",
      "AUPR_entropy: 96.52\n",
      "AUROC_entropy: 97.01\n",
      "AUPR_MI: 97.26\n",
      "AUROC_MI: 97.6\n",
      "############################################\n",
      "time 8400 9811.389907836914 test accuracy:  0.9916 0.9891\n",
      "maxp_OOD: 0.012717391304347826 0.6084213120473373 0.20635573416359337\n",
      "maxp_inD: 0.7185 0.9742724495037893 0.07342837076713771\n",
      "ent_OOD: 1.0922064613015718 0.4765931768186402 ent_in: 0.100191368727198 0.20032051192159314\n",
      "MI_OOD: 0.0863987397684908 0.047079843722299654 ent_in: 0.006099997007244961 0.014872943522936166\n",
      "AUPR_p: 96.21\n",
      "AUROC_p: 96.91\n",
      "AUPR_entropy: 96.76\n",
      "AUROC_entropy: 97.2\n",
      "AUPR_MI: 96.67\n",
      "AUROC_MI: 97.18\n",
      "############################################\n",
      "time 9000 10563.6810297966 test accuracy:  0.992 0.9858\n",
      "maxp_OOD: 0.012065217391304348 0.6093389509495793 0.2063202730480089\n",
      "maxp_inD: 0.7278 0.9750026230535779 0.07211826561567802\n",
      "ent_OOD: 1.0901618717562134 0.47454983649686416 ent_in: 0.09671085191196246 0.197583111272166\n",
      "MI_OOD: 0.08458192146679785 0.044416548886034045 ent_in: 0.005510452428987883 0.013608628077014519\n",
      "AUPR_p: 96.39\n",
      "AUROC_p: 97.02\n",
      "AUPR_entropy: 96.91\n",
      "AUROC_entropy: 97.33\n",
      "AUPR_MI: 97.18\n",
      "AUROC_MI: 97.58\n",
      "############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 9600 11241.188015699387 test accuracy:  0.9919 0.9902\n",
      "maxp_OOD: 0.012717391304347826 0.6173743001212791 0.20669767333492764\n",
      "maxp_inD: 0.7205 0.9750633994874482 0.07192159715234635\n",
      "ent_OOD: 1.0646984829355615 0.47423794250645657 ent_in: 0.09729631324086038 0.19818311451866205\n",
      "MI_OOD: 0.09814944504144266 0.05376531672112237 ent_in: 0.0065809815938212965 0.016336204084232153\n",
      "AUPR_p: 96.17\n",
      "AUROC_p: 96.87\n",
      "AUPR_entropy: 96.65\n",
      "AUROC_entropy: 97.13\n",
      "AUPR_MI: 96.89\n",
      "AUROC_MI: 97.35\n",
      "############################################\n",
      "time 10200 11970.819443941116 test accuracy:  0.9911 0.9895\n",
      "maxp_OOD: 0.014456521739130436 0.6206263532788642 0.2081953849975753\n",
      "maxp_inD: 0.7163 0.9752856095224992 0.07131735828227011\n",
      "ent_OOD: 1.055435850219194 0.47902389051299465 ent_in: 0.09711602399275997 0.19664414928895407\n",
      "MI_OOD: 0.08958321289932702 0.048768809572007854 ent_in: 0.005527886739606645 0.013772738391995965\n",
      "AUPR_p: 96.02\n",
      "AUROC_p: 96.69\n",
      "AUPR_entropy: 96.5\n",
      "AUROC_entropy: 96.94\n",
      "AUPR_MI: 97.2\n",
      "AUROC_MI: 97.53\n",
      "############################################\n",
      "time 10800 12667.014138698578 test accuracy:  0.9914 0.9898\n",
      "maxp_OOD: 0.013695652173913043 0.6101617779720496 0.20690075851588838\n",
      "maxp_inD: 0.7154 0.9749476997310172 0.07239001400201892\n",
      "ent_OOD: 1.0763485004684723 0.47301562754290205 ent_in: 0.09870722825087684 0.20041566287556725\n",
      "MI_OOD: 0.10175894397088976 0.05560797147648945 ent_in: 0.006307907808340472 0.015109591882215332\n",
      "AUPR_p: 96.25\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.63\n",
      "AUROC_entropy: 97.13\n",
      "AUPR_MI: 97.36\n",
      "AUROC_MI: 97.64\n",
      "############################################\n",
      "time 11400 13387.394043922424 test accuracy:  0.9914 0.9904\n",
      "maxp_OOD: 0.013478260869565217 0.6162597874497786 0.2079761825738818\n",
      "maxp_inD: 0.7396 0.975499560434806 0.07258373855496345\n",
      "ent_OOD: 1.0670783120208778 0.477447023909701 ent_in: 0.09388360801308529 0.1974052129669861\n",
      "MI_OOD: 0.08968594271795155 0.04872999526850371 ent_in: 0.0061953496978528685 0.015848894873922166\n",
      "AUPR_p: 96.17\n",
      "AUROC_p: 96.86\n",
      "AUPR_entropy: 96.69\n",
      "AUROC_entropy: 97.15\n",
      "AUPR_MI: 96.59\n",
      "AUROC_MI: 97.2\n",
      "############################################\n",
      "time 12000 14094.85542678833 test accuracy:  0.9905 0.9872\n",
      "maxp_OOD: 0.018260869565217393 0.6190918193165335 0.2078216270684867\n",
      "maxp_inD: 0.7261 0.9744845888597643 0.0748309783636677\n",
      "ent_OOD: 1.0521860837662598 0.47985880676924086 ent_in: 0.0990221352498487 0.2041101468897753\n",
      "MI_OOD: 0.08249716015191201 0.045358882094318036 ent_in: 0.006586141542850899 0.016065446169709965\n",
      "AUPR_p: 95.71\n",
      "AUROC_p: 96.55\n",
      "AUPR_entropy: 96.16\n",
      "AUROC_entropy: 96.75\n",
      "AUPR_MI: 95.85\n",
      "AUROC_MI: 96.63\n",
      "############################################\n",
      "time 12600 14765.309589862823 test accuracy:  0.9918 0.9912\n",
      "maxp_OOD: 0.01358695652173913 0.6179711599615132 0.20691347726115333\n",
      "maxp_inD: 0.7395 0.9763534583093475 0.07018820787351815\n",
      "ent_OOD: 1.061411360787067 0.47504194585774967 ent_in: 0.09260617639944245 0.19401458614033606\n",
      "MI_OOD: 0.08399790686154937 0.04449905217712434 ent_in: 0.0052546090233918435 0.013521827798532771\n",
      "AUPR_p: 96.3\n",
      "AUROC_p: 96.97\n",
      "AUPR_entropy: 96.72\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 97.14\n",
      "AUROC_MI: 97.57\n",
      "############################################\n",
      "time 13200 15463.338639736176 test accuracy:  0.9916 0.9908\n",
      "maxp_OOD: 0.015869565217391305 0.6195160737817962 0.20878413662365083\n",
      "maxp_inD: 0.7345 0.9762544283265745 0.0699149948854956\n",
      "ent_OOD: 1.0547302632326938 0.48122910965492083 ent_in: 0.0927426416676272 0.19243680643939787\n",
      "MI_OOD: 0.09773381657897921 0.054674071459415094 ent_in: 0.005653512464187633 0.01422014905780208\n",
      "AUPR_p: 96.17\n",
      "AUROC_p: 96.78\n",
      "AUPR_entropy: 96.61\n",
      "AUROC_entropy: 97.02\n",
      "AUPR_MI: 97.34\n",
      "AUROC_MI: 97.57\n",
      "############################################\n",
      "time 13800 16162.600520849228 test accuracy:  0.991 0.9891\n",
      "maxp_OOD: 0.014782608695652174 0.6187315311434954 0.20736514894862995\n",
      "maxp_inD: 0.7555 0.9770748955209554 0.06947292534896403\n",
      "ent_OOD: 1.06249469704818 0.4759360951632534 ent_in: 0.08859385531611728 0.19009275734033282\n",
      "MI_OOD: 0.08857144774574932 0.048406759692527314 ent_in: 0.0049541027255880846 0.012604435942716659\n",
      "AUPR_p: 96.38\n",
      "AUROC_p: 97.03\n",
      "AUPR_entropy: 96.89\n",
      "AUROC_entropy: 97.31\n",
      "AUPR_MI: 97.56\n",
      "AUROC_MI: 97.8\n",
      "############################################\n",
      "time 14400 16860.882950782776 test accuracy:  0.9922 0.9895\n",
      "maxp_OOD: 0.015543478260869565 0.617248011256585 0.20703348939410712\n",
      "maxp_inD: 0.7318 0.9752085949729755 0.07340284653032789\n",
      "ent_OOD: 1.059943335246025 0.47563497376284086 ent_in: 0.0958109209093236 0.19906136183050763\n",
      "MI_OOD: 0.09078450220512395 0.04997181041730266 ent_in: 0.006796132301373772 0.01627709185241939\n",
      "AUPR_p: 96.0\n",
      "AUROC_p: 96.75\n",
      "AUPR_entropy: 96.52\n",
      "AUROC_entropy: 97.02\n",
      "AUPR_MI: 96.32\n",
      "AUROC_MI: 96.83\n",
      "############################################\n",
      "time 15000 17573.537969827652 test accuracy:  0.9906 0.9882\n",
      "maxp_OOD: 0.012934782608695652 0.6142815537819829 0.20784080315360845\n",
      "maxp_inD: 0.7362 0.9753949411283432 0.07194340440482312\n",
      "ent_OOD: 1.069184488572219 0.47530967273954566 ent_in: 0.09471144082380763 0.19749026549831905\n",
      "MI_OOD: 0.09532926723565704 0.05193167547359757 ent_in: 0.006154998442766003 0.01505471962721431\n",
      "AUPR_p: 96.26\n",
      "AUROC_p: 96.91\n",
      "AUPR_entropy: 96.74\n",
      "AUROC_entropy: 97.18\n",
      "AUPR_MI: 97.1\n",
      "AUROC_MI: 97.43\n",
      "############################################\n",
      "time 15600 18284.9684548378 test accuracy:  0.9919 0.988\n",
      "maxp_OOD: 0.013804347826086957 0.6161548987260963 0.20737745027071225\n",
      "maxp_inD: 0.7352 0.9758642040377111 0.07125526224865286\n",
      "ent_OOD: 1.0668107201447896 0.47740192707322915 ent_in: 0.09358203237005004 0.19550748896271034\n",
      "MI_OOD: 0.09708256640174429 0.05272011649192507 ent_in: 0.0061352205495057086 0.015723310466270395\n",
      "AUPR_p: 96.28\n",
      "AUROC_p: 96.9\n",
      "AUPR_entropy: 96.72\n",
      "AUROC_entropy: 97.15\n",
      "AUPR_MI: 97.05\n",
      "AUROC_MI: 97.46\n",
      "############################################\n",
      "time 16200 18984.49044394493 test accuracy:  0.9917 0.9908\n",
      "maxp_OOD: 0.01641304347826087 0.6194386322789714 0.20802696960699477\n",
      "maxp_inD: 0.7466 0.9760316623747162 0.07275790114920613\n",
      "ent_OOD: 1.05616643346741 0.47862787911016597 ent_in: 0.09139875190849509 0.19660045476851715\n",
      "MI_OOD: 0.0952749369245802 0.053163708492778176 ent_in: 0.006577331208873727 0.01716272094589426\n",
      "AUPR_p: 96.03\n",
      "AUROC_p: 96.73\n",
      "AUPR_entropy: 96.57\n",
      "AUROC_entropy: 97.01\n",
      "AUPR_MI: 96.36\n",
      "AUROC_MI: 96.96\n",
      "############################################\n",
      "time 16800 19685.884227752686 test accuracy:  0.9918 0.989\n",
      "maxp_OOD: 0.011956521739130435 0.6114521862415164 0.20554103662141207\n",
      "maxp_inD: 0.7517 0.9764470249343663 0.07165045738331308\n",
      "ent_OOD: 1.079707305114011 0.46923544503275794 ent_in: 0.09049811210244492 0.19515141159149346\n",
      "MI_OOD: 0.10737911211547763 0.05721043945443904 ent_in: 0.005833758427182385 0.015204589219579503\n",
      "AUPR_p: 96.47\n",
      "AUROC_p: 97.18\n",
      "AUPR_entropy: 96.98\n",
      "AUROC_entropy: 97.45\n",
      "AUPR_MI: 97.71\n",
      "AUROC_MI: 97.99\n",
      "############################################\n",
      "time 17400 20389.584045648575 test accuracy:  0.9919 0.9923\n",
      "maxp_OOD: 0.014130434782608696 0.6194121702075818 0.20532131585060126\n",
      "maxp_inD: 0.756 0.9771544652882963 0.06970411347968336\n",
      "ent_OOD: 1.0553086076385796 0.4702036885388138 ent_in: 0.088012023624189 0.19050250732613447\n",
      "MI_OOD: 0.10075655911122186 0.054430024534135805 ent_in: 0.0063865005317410625 0.01655410403568247\n",
      "AUPR_p: 96.42\n",
      "AUROC_p: 97.09\n",
      "AUPR_entropy: 96.9\n",
      "AUROC_entropy: 97.34\n",
      "AUPR_MI: 97.0\n",
      "AUROC_MI: 97.43\n",
      "############################################\n",
      "time 18000 21081.933784008026 test accuracy:  0.9923 0.9904\n",
      "maxp_OOD: 0.015 0.6145162750182477 0.20723230569227383\n",
      "maxp_inD: 0.7404 0.9765647606266166 0.07060157734760548\n",
      "ent_OOD: 1.0638847091165051 0.4740195393440311 ent_in: 0.09101461411742809 0.1915367296964875\n",
      "MI_OOD: 0.10330564281642823 0.05703458168555017 ent_in: 0.00563528699599473 0.013989230631882496\n",
      "AUPR_p: 96.34\n",
      "AUROC_p: 96.96\n",
      "AUPR_entropy: 96.8\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 97.67\n",
      "AUROC_MI: 97.83\n",
      "############################################\n",
      "time 18600 21776.096579790115 test accuracy:  0.992 0.9917\n",
      "maxp_OOD: 0.01608695652173913 0.6206307703275435 0.20770596868872487\n",
      "maxp_inD: 0.7359 0.9766064172824225 0.06925222808378344\n",
      "ent_OOD: 1.051406544502337 0.4781773455275953 ent_in: 0.09150078804167708 0.1903727485682387\n",
      "MI_OOD: 0.09862354697092693 0.054109582473287565 ent_in: 0.006048617718581236 0.01490964118436213\n",
      "AUPR_p: 96.24\n",
      "AUROC_p: 96.77\n",
      "AUPR_entropy: 96.66\n",
      "AUROC_entropy: 97.02\n",
      "AUPR_MI: 97.19\n",
      "AUROC_MI: 97.43\n",
      "############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 19200 22482.58616089821 test accuracy:  0.9909 0.9892\n",
      "maxp_OOD: 0.014239130434782608 0.616284687332043 0.20562166303627477\n",
      "maxp_inD: 0.7381 0.9758080632079642 0.07307834038216496\n",
      "ent_OOD: 1.0541700299021408 0.46945434168029476 ent_in: 0.09256410530660779 0.19587593581154358\n",
      "MI_OOD: 0.09537376164632985 0.05182935412889033 ent_in: 0.006274415736928681 0.01580538346304773\n",
      "AUPR_p: 96.16\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.68\n",
      "AUROC_entropy: 97.19\n",
      "AUPR_MI: 96.93\n",
      "AUROC_MI: 97.37\n",
      "############################################\n",
      "time 19800 23189.10094690323 test accuracy:  0.9912 0.9899\n",
      "maxp_OOD: 0.01608695652173913 0.6228036112926151 0.20648180824843282\n",
      "maxp_inD: 0.7222 0.9756241749636332 0.07206603473312252\n",
      "ent_OOD: 1.0400312828744565 0.47297220122546874 ent_in: 0.09444973170614623 0.19419317845032447\n",
      "MI_OOD: 0.10058812943366298 0.054970910936970784 ent_in: 0.006220984771098369 0.015547911967065838\n",
      "AUPR_p: 95.92\n",
      "AUROC_p: 96.72\n",
      "AUPR_entropy: 96.48\n",
      "AUROC_entropy: 96.97\n",
      "AUPR_MI: 97.15\n",
      "AUROC_MI: 97.47\n",
      "############################################\n",
      "time 20400 23881.46447277069 test accuracy:  0.9925 0.9912\n",
      "maxp_OOD: 0.01576086956521739 0.6206960085289572 0.20628450516423594\n",
      "maxp_inD: 0.7428 0.9770789609205848 0.06962947291158249\n",
      "ent_OOD: 1.0473441836648592 0.47112182587029705 ent_in: 0.08970528678035808 0.19211408024321186\n",
      "MI_OOD: 0.101703475286591 0.05692282889434566 ent_in: 0.005253751237508486 0.013533512160151516\n",
      "AUPR_p: 96.27\n",
      "AUROC_p: 96.92\n",
      "AUPR_entropy: 96.65\n",
      "AUROC_entropy: 97.12\n",
      "AUPR_MI: 97.68\n",
      "AUROC_MI: 97.85\n",
      "############################################\n",
      "time 21000 24592.449898958206 test accuracy:  0.992 0.9897\n",
      "maxp_OOD: 0.01641304347826087 0.6208804922311836 0.2065404525557191\n",
      "maxp_inD: 0.7601 0.9774209373143625 0.07012516561098983\n",
      "ent_OOD: 1.0499932890892714 0.47340904515496235 ent_in: 0.08656692214221985 0.1892827942730311\n",
      "MI_OOD: 0.0998502401303645 0.05313695518695796 ent_in: 0.006066200585180481 0.01589488686377681\n",
      "AUPR_p: 96.28\n",
      "AUROC_p: 96.99\n",
      "AUPR_entropy: 96.81\n",
      "AUROC_entropy: 97.26\n",
      "AUPR_MI: 97.16\n",
      "AUROC_MI: 97.54\n",
      "############################################\n",
      "time 21600 25304.871469020844 test accuracy:  0.9922 0.9909\n",
      "maxp_OOD: 0.01532608695652174 0.6177889241018093 0.20626496858516588\n",
      "maxp_inD: 0.7359 0.9762976656610146 0.0706736062901814\n",
      "ent_OOD: 1.0534960549153372 0.4719442329942187 ent_in: 0.09328226276521202 0.19407618636877294\n",
      "MI_OOD: 0.09906513557413024 0.05231536304984356 ent_in: 0.005855251754501882 0.014597235157033747\n",
      "AUPR_p: 96.24\n",
      "AUROC_p: 96.92\n",
      "AUPR_entropy: 96.64\n",
      "AUROC_entropy: 97.12\n",
      "AUPR_MI: 97.49\n",
      "AUROC_MI: 97.73\n",
      "############################################\n",
      "time 22200 26017.479509830475 test accuracy:  0.9922 0.9905\n",
      "maxp_OOD: 0.0175 0.6240051935849428 0.20831890825688662\n",
      "maxp_inD: 0.7651 0.9780065872391002 0.06860648538384406\n",
      "ent_OOD: 1.0421476427970333 0.47732234429209697 ent_in: 0.08471253985322443 0.18742903148541123\n",
      "MI_OOD: 0.08916244580194797 0.05019095675034996 ent_in: 0.005830096120382269 0.015510486050482468\n",
      "AUPR_p: 96.29\n",
      "AUROC_p: 96.9\n",
      "AUPR_entropy: 96.75\n",
      "AUROC_entropy: 97.16\n",
      "AUPR_MI: 96.54\n",
      "AUROC_MI: 97.1\n",
      "############################################\n",
      "time 22800 26719.596767902374 test accuracy:  0.9923 0.9906\n",
      "maxp_OOD: 0.01717391304347826 0.6218477475379115 0.20744992312749827\n",
      "maxp_inD: 0.7584 0.9777158475630978 0.06877808706782713\n",
      "ent_OOD: 1.047685300574125 0.4754258517540011 ent_in: 0.08690604607076187 0.18821515368546118\n",
      "MI_OOD: 0.1020525788830273 0.0560109147569399 ent_in: 0.00551851300174461 0.014250447445572639\n",
      "AUPR_p: 96.35\n",
      "AUROC_p: 96.95\n",
      "AUPR_entropy: 96.75\n",
      "AUROC_entropy: 97.18\n",
      "AUPR_MI: 97.53\n",
      "AUROC_MI: 97.75\n",
      "############################################\n",
      "time 23400 27432.432809829712 test accuracy:  0.9918 0.9917\n",
      "maxp_OOD: 0.014021739130434783 0.6219945703721437 0.20605054582031612\n",
      "maxp_inD: 0.7463 0.9771314265091096 0.06966922267562951\n",
      "ent_OOD: 1.044661089522906 0.4709253310101437 ent_in: 0.08947665421236788 0.19105829226233584\n",
      "MI_OOD: 0.0916200452917134 0.05027967561261097 ent_in: 0.00592643472630913 0.01476936568520728\n",
      "AUPR_p: 96.29\n",
      "AUROC_p: 96.99\n",
      "AUPR_entropy: 96.71\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 97.02\n",
      "AUROC_MI: 97.4\n",
      "############################################\n",
      "time 24000 28137.912911891937 test accuracy:  0.9917 0.9913\n",
      "maxp_OOD: 0.01576086956521739 0.6225715350872784 0.20545719182769634\n",
      "maxp_inD: 0.7375 0.9771498065666606 0.06841446268706843\n",
      "ent_OOD: 1.041975647907612 0.4690628003594754 ent_in: 0.09028596276034548 0.18803838376034482\n",
      "MI_OOD: 0.09919866662776673 0.05397594693987921 ent_in: 0.0052701535475959856 0.013198469502987975\n",
      "AUPR_p: 96.28\n",
      "AUROC_p: 96.95\n",
      "AUPR_entropy: 96.73\n",
      "AUROC_entropy: 97.17\n",
      "AUPR_MI: 97.76\n",
      "AUROC_MI: 97.91\n",
      "############################################\n",
      "time 24600 28846.634624004364 test accuracy:  0.9925 0.9924\n",
      "maxp_OOD: 0.013804347826086957 0.6131880775910676 0.20587711267018577\n",
      "maxp_inD: 0.7546 0.9777852505401026 0.06784759823357593\n",
      "ent_OOD: 1.0696619471135775 0.47127942695836683 ent_in: 0.08680947327989051 0.1857849445731605\n",
      "MI_OOD: 0.10281534349025367 0.05592441485007566 ent_in: 0.0056179137843238745 0.014280213461906142\n",
      "AUPR_p: 96.63\n",
      "AUROC_p: 97.2\n",
      "AUPR_entropy: 97.07\n",
      "AUROC_entropy: 97.45\n",
      "AUPR_MI: 97.62\n",
      "AUROC_MI: 97.83\n",
      "############################################\n",
      "time 25200 29538.06007885933 test accuracy:  0.9923 0.9921\n",
      "maxp_OOD: 0.016195652173913045 0.6203143880759346 0.2065468391709726\n",
      "maxp_inD: 0.7538 0.9771632814254985 0.07014213659405623\n",
      "ent_OOD: 1.0487513013365126 0.4717659311586491 ent_in: 0.08867871618924696 0.19171322394333093\n",
      "MI_OOD: 0.10110905374666587 0.05608941185002031 ent_in: 0.005996814459035133 0.015685433431670143\n",
      "AUPR_p: 96.27\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.7\n",
      "AUROC_entropy: 97.17\n",
      "AUPR_MI: 97.15\n",
      "AUROC_MI: 97.48\n",
      "############################################\n",
      "time 25800 30185.021672964096 test accuracy:  0.992 0.9903\n",
      "maxp_OOD: 0.017282608695652173 0.6191587249007163 0.20765996860089195\n",
      "maxp_inD: 0.7551 0.9776418155725672 0.06957759720979312\n",
      "ent_OOD: 1.0515009946701717 0.4756043337116564 ent_in: 0.08670182178114322 0.18973371315498738\n",
      "MI_OOD: 0.09801664909728733 0.0533134747133023 ent_in: 0.0057678315464642456 0.015473146645151781\n",
      "AUPR_p: 96.32\n",
      "AUROC_p: 96.99\n",
      "AUPR_entropy: 96.77\n",
      "AUROC_entropy: 97.2\n",
      "AUPR_MI: 97.14\n",
      "AUROC_MI: 97.53\n",
      "############################################\n",
      "time 26400 30822.668093919754 test accuracy:  0.9911 0.9905\n",
      "maxp_OOD: 0.016304347826086956 0.6206230694156384 0.20643663382612318\n",
      "maxp_inD: 0.7427 0.9767535152906055 0.06995864388364305\n",
      "ent_OOD: 1.0450885774875283 0.4720450161257117 ent_in: 0.09095579213899316 0.19104648564108995\n",
      "MI_OOD: 0.10140690523359429 0.05555154858774163 ent_in: 0.00668327450581422 0.016898874863478026\n",
      "AUPR_p: 96.23\n",
      "AUROC_p: 96.9\n",
      "AUPR_entropy: 96.65\n",
      "AUROC_entropy: 97.12\n",
      "AUPR_MI: 96.79\n",
      "AUROC_MI: 97.2\n",
      "############################################\n",
      "time 27000 31444.570450782776 test accuracy:  0.9921 0.991\n",
      "maxp_OOD: 0.01641304347826087 0.624896698298098 0.2074424140205898\n",
      "maxp_inD: 0.7533 0.9777426020648207 0.06868155540076121\n",
      "ent_OOD: 1.0342016012386315 0.47602272453425426 ent_in: 0.08671614967796226 0.187346614850571\n",
      "MI_OOD: 0.09343374952891183 0.05184483188380143 ent_in: 0.005412184203027595 0.013704915363662074\n",
      "AUPR_p: 96.23\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.69\n",
      "AUROC_entropy: 97.15\n",
      "AUPR_MI: 97.32\n",
      "AUROC_MI: 97.58\n",
      "############################################\n",
      "time 27600 32066.997515916824 test accuracy:  0.9917 0.9913\n",
      "maxp_OOD: 0.015869565217391305 0.6182293089956916 0.20847418689594172\n",
      "maxp_inD: 0.7455 0.9771641551440953 0.06884894527979955\n",
      "ent_OOD: 1.0596089434064766 0.47895317812034155 ent_in: 0.08961645616243404 0.18919175275912342\n",
      "MI_OOD: 0.10551530947038305 0.05822643660492787 ent_in: 0.005864222334119063 0.014777305636335827\n",
      "AUPR_p: 96.34\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.79\n",
      "AUROC_entropy: 97.18\n",
      "AUPR_MI: 97.51\n",
      "AUROC_MI: 97.7\n",
      "############################################\n",
      "time 28200 32690.57371377945 test accuracy:  0.9927 0.9908\n",
      "maxp_OOD: 0.016304347826086956 0.61968885740696 0.2072253668063287\n",
      "maxp_inD: 0.7674 0.9782531203852842 0.06814109668781976\n",
      "ent_OOD: 1.0536662316099505 0.4754091278874771 ent_in: 0.08387943481821754 0.18546861207867246\n",
      "MI_OOD: 0.10166202010511949 0.05694853347130636 ent_in: 0.005548333649871855 0.014910669935971144\n",
      "AUPR_p: 96.46\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.91\n",
      "AUROC_entropy: 97.31\n",
      "AUPR_MI: 97.34\n",
      "AUROC_MI: 97.62\n",
      "############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 28800 33315.09865689278 test accuracy:  0.9923 0.9918\n",
      "maxp_OOD: 0.018043478260869564 0.6229384314001275 0.20678399857768529\n",
      "maxp_inD: 0.7615 0.9779319658582037 0.06925058537118124\n",
      "ent_OOD: 1.0408189237553402 0.4742205748959431 ent_in: 0.08543262521537438 0.1875767336890995\n",
      "MI_OOD: 0.09727185829494532 0.05292305281450538 ent_in: 0.005424490987054507 0.014246973321467024\n",
      "AUPR_p: 96.29\n",
      "AUROC_p: 96.94\n",
      "AUPR_entropy: 96.73\n",
      "AUROC_entropy: 97.18\n",
      "AUPR_MI: 97.42\n",
      "AUROC_MI: 97.67\n",
      "############################################\n",
      "time 29400 33943.80496263504 test accuracy:  0.9927 0.9909\n",
      "maxp_OOD: 0.01847826086956522 0.6236923044836841 0.20765985943182338\n",
      "maxp_inD: 0.7587 0.9777528466622283 0.06886885745048028\n",
      "ent_OOD: 1.0398972695105542 0.47611942128302126 ent_in: 0.08643727378024625 0.18722537542997916\n",
      "MI_OOD: 0.09627575588486263 0.053551594134927306 ent_in: 0.005826678444262449 0.015061587043921848\n",
      "AUPR_p: 96.22\n",
      "AUROC_p: 96.86\n",
      "AUPR_entropy: 96.69\n",
      "AUROC_entropy: 97.1\n",
      "AUPR_MI: 97.03\n",
      "AUROC_MI: 97.33\n",
      "############################################\n",
      "time 30000 34571.599450826645 test accuracy:  0.9923 0.9903\n",
      "maxp_OOD: 0.016304347826086956 0.6205040853423787 0.20760060535164637\n",
      "maxp_inD: 0.7551 0.9774639667147585 0.06968398646947155\n",
      "ent_OOD: 1.0496978501912084 0.4757492151534863 ent_in: 0.08725192820200765 0.18998584883295944\n",
      "MI_OOD: 0.0963761619730883 0.05278407738468026 ent_in: 0.0061333467853195945 0.016218244654101686\n",
      "AUPR_p: 96.32\n",
      "AUROC_p: 96.98\n",
      "AUPR_entropy: 96.76\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 96.86\n",
      "AUROC_MI: 97.35\n",
      "############################################\n",
      "time 30600 35200.66862273216 test accuracy:  0.9923 0.9913\n",
      "maxp_OOD: 0.014673913043478261 0.615993641166958 0.20559931020547953\n",
      "maxp_inD: 0.7619 0.9779824084359409 0.06918073324468098\n",
      "ent_OOD: 1.0607743041410904 0.4701402454171975 ent_in: 0.08510703824753257 0.18834616016455516\n",
      "MI_OOD: 0.10538317277260617 0.056240675991053965 ent_in: 0.005783887489727173 0.01523548327301931\n",
      "AUPR_p: 96.55\n",
      "AUROC_p: 97.18\n",
      "AUPR_entropy: 96.97\n",
      "AUROC_entropy: 97.41\n",
      "AUPR_MI: 97.57\n",
      "AUROC_MI: 97.83\n",
      "############################################\n",
      "time 31200 35815.12873291969 test accuracy:  0.9928 0.9912\n",
      "maxp_OOD: 0.017608695652173913 0.6246444772210755 0.20734020022685903\n",
      "maxp_inD: 0.7669 0.9783458403520039 0.0678219088052733\n",
      "ent_OOD: 1.0384639938786502 0.47460536269755554 ent_in: 0.08392390549500037 0.18464854314176812\n",
      "MI_OOD: 0.10642209231630848 0.05800729942660771 ent_in: 0.005258070556412293 0.013811909735905388\n",
      "AUPR_p: 96.34\n",
      "AUROC_p: 96.98\n",
      "AUPR_entropy: 96.8\n",
      "AUROC_entropy: 97.23\n",
      "AUPR_MI: 97.84\n",
      "AUROC_MI: 98.0\n",
      "############################################\n",
      "time 31800 36405.073747873306 test accuracy:  0.9925 0.9906\n",
      "maxp_OOD: 0.016195652173913045 0.6214764154073581 0.20716998529693498\n",
      "maxp_inD: 0.7588 0.9781348261030763 0.06759756518697753\n",
      "ent_OOD: 1.0464598892622567 0.4755607528258709 ent_in: 0.08570611515884048 0.18554459599318204\n",
      "MI_OOD: 0.09744457555234631 0.052947606059664476 ent_in: 0.005205642891087804 0.013573566318916682\n",
      "AUPR_p: 96.46\n",
      "AUROC_p: 97.03\n",
      "AUPR_entropy: 96.84\n",
      "AUROC_entropy: 97.25\n",
      "AUPR_MI: 97.59\n",
      "AUROC_MI: 97.78\n",
      "############################################\n",
      "time 32400 37018.995775938034 test accuracy:  0.9928 0.9917\n",
      "maxp_OOD: 0.015978260869565216 0.6209981172060884 0.20611146760719934\n",
      "maxp_inD: 0.757 0.9777642158097649 0.06866738074998364\n",
      "ent_OOD: 1.0482142880777334 0.47174336998510663 ent_in: 0.08621964258599679 0.18746932453582335\n",
      "MI_OOD: 0.09332938357905621 0.051069554906079305 ent_in: 0.005829825098148677 0.015212138732679547\n",
      "AUPR_p: 96.41\n",
      "AUROC_p: 97.02\n",
      "AUPR_entropy: 96.84\n",
      "AUROC_entropy: 97.27\n",
      "AUPR_MI: 96.99\n",
      "AUROC_MI: 97.42\n",
      "############################################\n",
      "time 33000 37636.76069188118 test accuracy:  0.9919 0.9921\n",
      "maxp_OOD: 0.014456521739130436 0.6165625039373854 0.2054220114976878\n",
      "maxp_inD: 0.7583 0.9777557221827781 0.06901503622064746\n",
      "ent_OOD: 1.0579910016905847 0.47010622785860934 ent_in: 0.08669369650831124 0.18807705367503308\n",
      "MI_OOD: 0.11020599733162972 0.062095362619653496 ent_in: 0.0058318078613888245 0.01546557325478654\n",
      "AUPR_p: 96.48\n",
      "AUROC_p: 97.16\n",
      "AUPR_entropy: 96.93\n",
      "AUROC_entropy: 97.38\n",
      "AUPR_MI: 97.58\n",
      "AUROC_MI: 97.86\n",
      "############################################\n",
      "time 33600 38256.284752845764 test accuracy:  0.9923 0.9882\n",
      "maxp_OOD: 0.01684782608695652 0.625067079516067 0.2071168365174789\n",
      "maxp_inD: 0.7587 0.978135271997278 0.06804394103165533\n",
      "ent_OOD: 1.0367423833865483 0.47445097029379313 ent_in: 0.08523878329865266 0.18537963310855007\n",
      "MI_OOD: 0.09312664995892918 0.051651421556128924 ent_in: 0.005537503567507712 0.01430302965542125\n",
      "AUPR_p: 96.32\n",
      "AUROC_p: 96.96\n",
      "AUPR_entropy: 96.77\n",
      "AUROC_entropy: 97.2\n",
      "AUPR_MI: 97.18\n",
      "AUROC_MI: 97.51\n",
      "############################################\n",
      "time 34200 38889.81592774391 test accuracy:  0.9922 0.9911\n",
      "maxp_OOD: 0.016739130434782607 0.6234413440922576 0.205945550357007\n",
      "maxp_inD: 0.7646 0.9781968900563072 0.06836688127552981\n",
      "ent_OOD: 1.0389524050010521 0.4708324100579828 ent_in: 0.08454105176115115 0.18621543593158038\n",
      "MI_OOD: 0.09650812296119135 0.05182128625137571 ent_in: 0.005502889703477707 0.014597025648611987\n",
      "AUPR_p: 96.4\n",
      "AUROC_p: 97.06\n",
      "AUPR_entropy: 96.82\n",
      "AUROC_entropy: 97.29\n",
      "AUPR_MI: 97.38\n",
      "AUROC_MI: 97.71\n",
      "############################################\n",
      "time 34800 39538.58235788345 test accuracy:  0.9927 0.991\n",
      "maxp_OOD: 0.018260869565217393 0.6270046258879711 0.2078422714541316\n",
      "maxp_inD: 0.7627 0.9779996520768105 0.06874884409669993\n",
      "ent_OOD: 1.033762916727781 0.4781815814647259 ent_in: 0.08513022722848625 0.18681902456787444\n",
      "MI_OOD: 0.09449490858890039 0.053128467541304854 ent_in: 0.005707669249172593 0.015096938729029721\n",
      "AUPR_p: 96.19\n",
      "AUROC_p: 96.82\n",
      "AUPR_entropy: 96.64\n",
      "AUROC_entropy: 97.07\n",
      "AUPR_MI: 96.93\n",
      "AUROC_MI: 97.31\n",
      "############################################\n",
      "time 35400 40167.252681970596 test accuracy:  0.9924 0.9915\n",
      "maxp_OOD: 0.01717391304347826 0.6235177354148245 0.20694198165530542\n",
      "maxp_inD: 0.7687 0.978497338461789 0.06745926769693089\n",
      "ent_OOD: 1.0390009629757357 0.4741607592844243 ent_in: 0.08380800853320629 0.1844743048490985\n",
      "MI_OOD: 0.0991918539343074 0.05394081415250493 ent_in: 0.00550375309633882 0.014575242845302138\n",
      "AUPR_p: 96.41\n",
      "AUROC_p: 97.03\n",
      "AUPR_entropy: 96.83\n",
      "AUROC_entropy: 97.25\n",
      "AUPR_MI: 97.44\n",
      "AUROC_MI: 97.71\n",
      "############################################\n",
      "time 36000 40804.42643404007 test accuracy:  0.9924 0.9906\n",
      "maxp_OOD: 0.014565217391304348 0.620708748700831 0.20658761110673443\n",
      "maxp_inD: 0.7561 0.9780260255735617 0.06817660019108211\n",
      "ent_OOD: 1.0486239606150412 0.4727480322207998 ent_in: 0.08617290845400381 0.1868357359850873\n",
      "MI_OOD: 0.09252805798000345 0.050490629062394536 ent_in: 0.005369320333292558 0.013986520350424773\n",
      "AUPR_p: 96.43\n",
      "AUROC_p: 97.1\n",
      "AUPR_entropy: 96.86\n",
      "AUROC_entropy: 97.31\n",
      "AUPR_MI: 97.33\n",
      "AUROC_MI: 97.65\n",
      "############################################\n",
      "time 36600 41427.3238966465 test accuracy:  0.9922 0.992\n",
      "maxp_OOD: 0.017391304347826087 0.6228874775502996 0.20710745290551227\n",
      "maxp_inD: 0.7671 0.9782527272638927 0.0688016083259319\n",
      "ent_OOD: 1.0434399895242736 0.47470011662955974 ent_in: 0.0841276356775765 0.18627013238619164\n",
      "MI_OOD: 0.09930486312086025 0.054074541528576374 ent_in: 0.004997245570575838 0.013512057545835988\n",
      "AUPR_p: 96.31\n",
      "AUROC_p: 96.96\n",
      "AUPR_entropy: 96.78\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 97.7\n",
      "AUROC_MI: 97.9\n",
      "############################################\n",
      "time 37200 42063.175501823425 test accuracy:  0.9927 0.9909\n",
      "maxp_OOD: 0.015978260869565216 0.6175435735982914 0.20687143106777048\n",
      "maxp_inD: 0.7615 0.9781683253180485 0.06808464469133527\n",
      "ent_OOD: 1.0588928290628783 0.4746531899708722 ent_in: 0.08522763578046433 0.18690461161515856\n",
      "MI_OOD: 0.10798753387263026 0.05861220570055151 ent_in: 0.005770240821161047 0.015210925442207809\n",
      "AUPR_p: 96.51\n",
      "AUROC_p: 97.11\n",
      "AUPR_entropy: 96.93\n",
      "AUROC_entropy: 97.33\n",
      "AUPR_MI: 97.6\n",
      "AUROC_MI: 97.83\n",
      "############################################\n",
      "time 37800 42699.76212978363 test accuracy:  0.9922 0.9916\n",
      "maxp_OOD: 0.01652173913043478 0.6226932386554089 0.20676882279419154\n",
      "maxp_inD: 0.7633 0.9782919490740697 0.06814357767412507\n",
      "ent_OOD: 1.0409441313537227 0.473345823067314 ent_in: 0.0844925443294998 0.18595391906498565\n",
      "MI_OOD: 0.09521892386649239 0.05366139092559428 ent_in: 0.005590435191354335 0.014612492816912351\n",
      "AUPR_p: 96.38\n",
      "AUROC_p: 97.01\n",
      "AUPR_entropy: 96.78\n",
      "AUROC_entropy: 97.23\n",
      "AUPR_MI: 97.12\n",
      "AUROC_MI: 97.45\n",
      "############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 38400 43342.6580889225 test accuracy:  0.9925 0.9898\n",
      "maxp_OOD: 0.015869565217391305 0.6196090112036293 0.20613630042843936\n",
      "maxp_inD: 0.7588 0.9777863082478939 0.06883264027395096\n",
      "ent_OOD: 1.0518016392931175 0.4720714934780724 ent_in: 0.08664224192922475 0.18866671137289784\n",
      "MI_OOD: 0.10499193818397695 0.056368210904810076 ent_in: 0.006260515628862019 0.016500866883321735\n",
      "AUPR_p: 96.41\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.82\n",
      "AUROC_entropy: 97.27\n",
      "AUPR_MI: 97.16\n",
      "AUROC_MI: 97.53\n",
      "############################################\n",
      "time 39000 43990.53603577614 test accuracy:  0.9921 0.9914\n",
      "maxp_OOD: 0.015434782608695652 0.6230009865210142 0.2051616202797403\n",
      "maxp_inD: 0.761 0.9778265194949383 0.06964687507925583\n",
      "ent_OOD: 1.039110084641119 0.46976848127887877 ent_in: 0.08560968750808244 0.1874467791509354\n",
      "MI_OOD: 0.09208371730946098 0.049772626746731934 ent_in: 0.005419151355708031 0.014541490411282543\n",
      "AUPR_p: 96.29\n",
      "AUROC_p: 97.06\n",
      "AUPR_entropy: 96.8\n",
      "AUROC_entropy: 97.3\n",
      "AUPR_MI: 97.2\n",
      "AUROC_MI: 97.61\n",
      "############################################\n",
      "time 39600 44626.9425008297 test accuracy:  0.9925 0.9905\n",
      "maxp_OOD: 0.01684782608695652 0.6263818128628595 0.20685371734195954\n",
      "maxp_inD: 0.771 0.9784099182420721 0.06863992437727214\n",
      "ent_OOD: 1.0313917790133864 0.47411847051958755 ent_in: 0.08312161881781112 0.18598997497472552\n",
      "MI_OOD: 0.0916831368474068 0.050126188952479514 ent_in: 0.005332922001924561 0.01440468850589968\n",
      "AUPR_p: 96.31\n",
      "AUROC_p: 96.98\n",
      "AUPR_entropy: 96.75\n",
      "AUROC_entropy: 97.22\n",
      "AUPR_MI: 97.16\n",
      "AUROC_MI: 97.54\n",
      "############################################\n",
      "time 40200 45253.49471592903 test accuracy:  0.9923 0.9911\n",
      "maxp_OOD: 0.014239130434782608 0.6190507424835291 0.20565023473365202\n",
      "maxp_inD: 0.7532 0.9777820324164007 0.06832393138990212\n",
      "ent_OOD: 1.0531598175047883 0.47005536678136267 ent_in: 0.08736165077762113 0.18748732948956442\n",
      "MI_OOD: 0.09968496760265785 0.0551018264329012 ent_in: 0.005784355010949648 0.014877287582447503\n",
      "AUPR_p: 96.46\n",
      "AUROC_p: 97.14\n",
      "AUPR_entropy: 96.89\n",
      "AUROC_entropy: 97.35\n",
      "AUPR_MI: 97.36\n",
      "AUROC_MI: 97.69\n",
      "############################################\n",
      "time 40800 45888.793838739395 test accuracy:  0.9925 0.9916\n",
      "maxp_OOD: 0.016739130434782607 0.6240383458535687 0.2078220559956584\n",
      "maxp_inD: 0.7586 0.9777569447759786 0.06881821416455754\n",
      "ent_OOD: 1.0405458924768411 0.4762113391164041 ent_in: 0.08666678903634283 0.18830240447498506\n",
      "MI_OOD: 0.09048119508884454 0.049020495346197894 ent_in: 0.005893844660615365 0.015524634771235049\n",
      "AUPR_p: 96.28\n",
      "AUROC_p: 96.9\n",
      "AUPR_entropy: 96.69\n",
      "AUROC_entropy: 97.13\n",
      "AUPR_MI: 96.74\n",
      "AUROC_MI: 97.25\n",
      "############################################\n",
      "time 41400 46529.57690691948 test accuracy:  0.992 0.9912\n",
      "maxp_OOD: 0.016630434782608696 0.622209448340035 0.20674336139116575\n",
      "maxp_inD: 0.7651 0.9783712575163569 0.06756655442653929\n",
      "ent_OOD: 1.0426661421024663 0.4741121183099223 ent_in: 0.08461150040487958 0.1855866639142282\n",
      "MI_OOD: 0.09750781802215601 0.05430699189897946 ent_in: 0.0054994794723959035 0.014468492198571678\n",
      "AUPR_p: 96.45\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.82\n",
      "AUROC_entropy: 97.26\n",
      "AUPR_MI: 97.32\n",
      "AUROC_MI: 97.62\n",
      "############################################\n",
      "time 42000 48889.120290756226 test accuracy:  0.9926 0.9917\n",
      "maxp_OOD: 0.016630434782608696 0.6211130634847761 0.20667694826014663\n",
      "maxp_inD: 0.775 0.9790228516743704 0.06680895884413302\n",
      "ent_OOD: 1.046545732213919 0.4724274115733503 ent_in: 0.08135325797806782 0.18293138915562962\n",
      "MI_OOD: 0.10107043678833676 0.05616591475562997 ent_in: 0.005180333057538675 0.014153369306004363\n",
      "AUPR_p: 96.59\n",
      "AUROC_p: 97.16\n",
      "AUPR_entropy: 96.98\n",
      "AUROC_entropy: 97.39\n",
      "AUPR_MI: 97.6\n",
      "AUROC_MI: 97.84\n",
      "############################################\n",
      "time 42600 49775.545853853226 test accuracy:  0.9924 0.9911\n",
      "maxp_OOD: 0.016739130434782607 0.6211076904081021 0.20709084636445277\n",
      "maxp_inD: 0.7683 0.9785340816306197 0.06724902738740283\n",
      "ent_OOD: 1.0487175600114709 0.4747377081873977 ent_in: 0.08373230891903125 0.18517380823622367\n",
      "MI_OOD: 0.10254949107704645 0.05631879522725159 ent_in: 0.005470073891332148 0.014506030687311022\n",
      "AUPR_p: 96.51\n",
      "AUROC_p: 97.08\n",
      "AUPR_entropy: 96.89\n",
      "AUROC_entropy: 97.3\n",
      "AUPR_MI: 97.54\n",
      "AUROC_MI: 97.78\n",
      "############################################\n",
      "time 43200 50408.19647884369 test accuracy:  0.9924 0.9911\n",
      "maxp_OOD: 0.016304347826086956 0.622159206091207 0.20700992703161786\n",
      "maxp_inD: 0.7659 0.9782707400717711 0.06874268922586468\n",
      "ent_OOD: 1.0437368781571854 0.4735701523566985 ent_in: 0.08438396676297401 0.18758183688714472\n",
      "MI_OOD: 0.0926815833180543 0.050771551464689126 ent_in: 0.0052254019426115775 0.014330385285683\n",
      "AUPR_p: 96.38\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.8\n",
      "AUROC_entropy: 97.27\n",
      "AUPR_MI: 97.26\n",
      "AUROC_MI: 97.66\n",
      "############################################\n",
      "time 43800 51091.27896499634 test accuracy:  0.9927 0.9914\n",
      "maxp_OOD: 0.015434782608695652 0.617333392118558 0.2063834099375201\n",
      "maxp_inD: 0.7674 0.9785653662737708 0.06759286407234408\n",
      "ent_OOD: 1.0560140293812446 0.4723460825238474 ent_in: 0.08324657310900394 0.18480836794956526\n",
      "MI_OOD: 0.10500965441762054 0.057174198498910915 ent_in: 0.005846685306936108 0.01545992989779127\n",
      "AUPR_p: 96.59\n",
      "AUROC_p: 97.17\n",
      "AUPR_entropy: 97.0\n",
      "AUROC_entropy: 97.4\n",
      "AUPR_MI: 97.42\n",
      "AUROC_MI: 97.71\n",
      "############################################\n",
      "time 44400 51978.46023774147 test accuracy:  0.9926 0.9915\n",
      "maxp_OOD: 0.015108695652173912 0.6166700485073539 0.20591662083206425\n",
      "maxp_inD: 0.7654 0.9783665132659672 0.06771039966605927\n",
      "ent_OOD: 1.0574378863821432 0.47093723226153517 ent_in: 0.08418696801426019 0.18548681399022637\n",
      "MI_OOD: 0.10860762425024333 0.06049260826491921 ent_in: 0.005503957412312158 0.014529686302622354\n",
      "AUPR_p: 96.62\n",
      "AUROC_p: 97.2\n",
      "AUPR_entropy: 97.0\n",
      "AUROC_entropy: 97.43\n",
      "AUPR_MI: 97.74\n",
      "AUROC_MI: 97.94\n",
      "############################################\n",
      "time 45000 52980.40781068802 test accuracy:  0.9922 0.991\n",
      "maxp_OOD: 0.015543478260869565 0.6183201078332512 0.20689351499490224\n",
      "maxp_inD: 0.7728 0.9787909169365963 0.06743166061211506\n",
      "ent_OOD: 1.0563032379489126 0.47447255339795885 ent_in: 0.08236680307331783 0.18515445640187964\n",
      "MI_OOD: 0.10779860532926414 0.05793894937994256 ent_in: 0.005291932276574254 0.014365627458674594\n",
      "AUPR_p: 96.61\n",
      "AUROC_p: 97.2\n",
      "AUPR_entropy: 97.0\n",
      "AUROC_entropy: 97.42\n",
      "AUPR_MI: 97.84\n",
      "AUROC_MI: 98.05\n",
      "############################################\n",
      "time 45600 53685.486797094345 test accuracy:  0.9924 0.9921\n",
      "maxp_OOD: 0.017391304347826087 0.6216484771234833 0.20763470465950218\n",
      "maxp_inD: 0.7709 0.9785248770435652 0.06750856298341384\n",
      "ent_OOD: 1.0456600912906588 0.47584287698398636 ent_in: 0.08351601716966098 0.18496674139797387\n",
      "MI_OOD: 0.10068947158589571 0.05680226250434963 ent_in: 0.005506716346488785 0.014319779476698583\n",
      "AUPR_p: 96.46\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.86\n",
      "AUROC_entropy: 97.28\n",
      "AUPR_MI: 97.45\n",
      "AUROC_MI: 97.69\n",
      "############################################\n",
      "time 46200 54340.26294589043 test accuracy:  0.9925 0.9911\n",
      "maxp_OOD: 0.015869565217391305 0.6219923296976393 0.20671563346656527\n",
      "maxp_inD: 0.7733 0.9789647184282044 0.06688535053322196\n",
      "ent_OOD: 1.04568712678804 0.47228799041641467 ent_in: 0.0816405566252179 0.18291619459855296\n",
      "MI_OOD: 0.09782880522629059 0.05364678576052263 ent_in: 0.0052282368164054144 0.014021246551547639\n",
      "AUPR_p: 96.57\n",
      "AUROC_p: 97.18\n",
      "AUPR_entropy: 96.98\n",
      "AUROC_entropy: 97.42\n",
      "AUPR_MI: 97.57\n",
      "AUROC_MI: 97.87\n",
      "############################################\n",
      "time 46800 55098.549274683 test accuracy:  0.9926 0.9901\n",
      "maxp_OOD: 0.015 0.619099810612334 0.20708788513062715\n",
      "maxp_inD: 0.7728 0.9788696903140346 0.06726375235719406\n",
      "ent_OOD: 1.054257816903437 0.474294737457966 ent_in: 0.08203069605659859 0.18380609062664371\n",
      "MI_OOD: 0.10103273197180612 0.05474935983882467 ent_in: 0.005181996343413086 0.013977750586002357\n",
      "AUPR_p: 96.61\n",
      "AUROC_p: 97.22\n",
      "AUPR_entropy: 97.03\n",
      "AUROC_entropy: 97.45\n",
      "AUPR_MI: 97.72\n",
      "AUROC_MI: 97.97\n",
      "############################################\n",
      "time 47400 55721.314416885376 test accuracy:  0.9925 0.9911\n",
      "maxp_OOD: 0.014891304347826087 0.6188572595701772 0.20552613028832212\n",
      "maxp_inD: 0.7592 0.9781120500901341 0.06838670679841694\n",
      "ent_OOD: 1.0500442803242234 0.469738197570017 ent_in: 0.0854959732813679 0.18710897251928452\n",
      "MI_OOD: 0.10544292401192751 0.055534460019137574 ent_in: 0.00522671695206435 0.013718244660959129\n",
      "AUPR_p: 96.48\n",
      "AUROC_p: 97.15\n",
      "AUPR_entropy: 96.89\n",
      "AUROC_entropy: 97.35\n",
      "AUPR_MI: 97.96\n",
      "AUROC_MI: 98.13\n",
      "############################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 48000 56352.772280693054 test accuracy:  0.9925 0.993\n",
      "maxp_OOD: 0.016630434782608696 0.6225520043478642 0.20676369438279393\n",
      "maxp_inD: 0.7773 0.9792824377643691 0.06617350008225657\n",
      "ent_OOD: 1.0425540616943947 0.47465809782220425 ent_in: 0.08069146430960704 0.18150087670134832\n",
      "MI_OOD: 0.10176170855432055 0.05658427163029741 ent_in: 0.004471865761118218 0.01237306667534165\n",
      "AUPR_p: 96.6\n",
      "AUROC_p: 97.16\n",
      "AUPR_entropy: 96.97\n",
      "AUROC_entropy: 97.38\n",
      "AUPR_MI: 98.01\n",
      "AUROC_MI: 98.15\n",
      "############################################\n",
      "time 48600 57141.54998278618 test accuracy:  0.9925 0.9915\n",
      "maxp_OOD: 0.015978260869565216 0.619555922605293 0.2063673009862141\n",
      "maxp_inD: 0.7607 0.9783325823144241 0.06749568841138359\n",
      "ent_OOD: 1.050205676621145 0.47243148761629233 ent_in: 0.08473835331165536 0.18494847523604277\n",
      "MI_OOD: 0.10331746765398606 0.05571735556106882 ent_in: 0.00545755129953996 0.014024152974268496\n",
      "AUPR_p: 96.54\n",
      "AUROC_p: 97.13\n",
      "AUPR_entropy: 96.94\n",
      "AUROC_entropy: 97.35\n",
      "AUPR_MI: 97.73\n",
      "AUROC_MI: 97.92\n",
      "############################################\n",
      "time 49200 57793.109259843826 test accuracy:  0.9925 0.9909\n",
      "maxp_OOD: 0.016630434782608696 0.6208433652313433 0.20675028918216964\n",
      "maxp_inD: 0.7638 0.9782935453482096 0.06792177827401216\n",
      "ent_OOD: 1.0478309493342741 0.47390022167650947 ent_in: 0.08453260627064896 0.1860641231152611\n",
      "MI_OOD: 0.09118807016398787 0.050024584711278054 ent_in: 0.005651625463254142 0.015250093745680073\n",
      "AUPR_p: 96.47\n",
      "AUROC_p: 97.08\n",
      "AUPR_entropy: 96.87\n",
      "AUROC_entropy: 97.3\n",
      "AUPR_MI: 96.86\n",
      "AUROC_MI: 97.35\n",
      "############################################\n",
      "time 49800 58424.69018793106 test accuracy:  0.9918 0.9915\n",
      "maxp_OOD: 0.013043478260869565 0.6179271221285706 0.20570035780712717\n",
      "maxp_inD: 0.7546 0.9778540028694274 0.06815126518888102\n",
      "ent_OOD: 1.053399775759837 0.4694354198543181 ent_in: 0.08681542294228785 0.18680482471036772\n",
      "MI_OOD: 0.10091553216109769 0.0542843079931808 ent_in: 0.005723193136216536 0.014904819917472814\n",
      "AUPR_p: 96.53\n",
      "AUROC_p: 97.16\n",
      "AUPR_entropy: 96.93\n",
      "AUROC_entropy: 97.38\n",
      "AUPR_MI: 97.5\n",
      "AUROC_MI: 97.84\n",
      "############################################\n",
      "time 50400 63107.02517390251 test accuracy:  0.9925 0.991\n",
      "maxp_OOD: 0.016304347826086956 0.62327799482402 0.2067219934323548\n",
      "maxp_inD: 0.7713 0.9786411102579161 0.06796482909480851\n",
      "ent_OOD: 1.0413959183431343 0.4734042818844271 ent_in: 0.08313247603481737 0.1857960690473168\n",
      "MI_OOD: 0.10436553689351365 0.056602028979375836 ent_in: 0.004642110423067656 0.012683126322252878\n",
      "AUPR_p: 96.43\n",
      "AUROC_p: 97.1\n",
      "AUPR_entropy: 96.83\n",
      "AUROC_entropy: 97.31\n",
      "AUPR_MI: 98.11\n",
      "AUROC_MI: 98.26\n",
      "############################################\n",
      "time 51000 63697.75036382675 test accuracy:  0.9927 0.9907\n",
      "maxp_OOD: 0.015434782608695652 0.6158813686903964 0.20687575618002146\n",
      "maxp_inD: 0.7661 0.978779145304064 0.0669104787109122\n",
      "ent_OOD: 1.0620986181469316 0.4746338395592531 ent_in: 0.08293635495702116 0.18374218151038957\n",
      "MI_OOD: 0.10657440714969033 0.0580532875008772 ent_in: 0.0047574109451516 0.012794428908203974\n",
      "AUPR_p: 96.64\n",
      "AUROC_p: 97.22\n",
      "AUPR_entropy: 97.05\n",
      "AUROC_entropy: 97.44\n",
      "AUPR_MI: 98.1\n",
      "AUROC_MI: 98.23\n",
      "############################################\n",
      "time 51600 64298.66603183746 test accuracy:  0.9927 0.9921\n",
      "maxp_OOD: 0.017391304347826087 0.6233009048462339 0.20758950948939445\n",
      "maxp_inD: 0.7642 0.9781463848492254 0.06857893142270069\n",
      "ent_OOD: 1.0396968143100607 0.47599309738318635 ent_in: 0.08515979422899539 0.18793130607887298\n",
      "MI_OOD: 0.09758753512347969 0.05450896775415556 ent_in: 0.005362435814762737 0.014426527258094091\n",
      "AUPR_p: 96.33\n",
      "AUROC_p: 96.96\n",
      "AUPR_entropy: 96.71\n",
      "AUROC_entropy: 97.17\n",
      "AUPR_MI: 97.31\n",
      "AUROC_MI: 97.6\n",
      "############################################\n",
      "time 52200 64963.612422943115 test accuracy:  0.9926 0.9915\n",
      "maxp_OOD: 0.018043478260869564 0.623335253222309 0.20765037575547396\n",
      "maxp_inD: 0.7663 0.9786032382661973 0.0672801532239676\n",
      "ent_OOD: 1.0392646050519034 0.474958453465749 ent_in: 0.08363968717154355 0.18408247731410213\n",
      "MI_OOD: 0.09811045097675086 0.05562231704634014 ent_in: 0.0054548435836473215 0.014297363619615122\n",
      "AUPR_p: 96.41\n",
      "AUROC_p: 96.99\n",
      "AUPR_entropy: 96.8\n",
      "AUROC_entropy: 97.21\n",
      "AUPR_MI: 97.32\n",
      "AUROC_MI: 97.58\n",
      "############################################\n",
      "time 52800 65579.04163789749 test accuracy:  0.9925 0.9913\n",
      "maxp_OOD: 0.017282608695652173 0.6243174938803497 0.2069557247085924\n",
      "maxp_inD: 0.7793 0.9793764739222328 0.06680583966858407\n",
      "ent_OOD: 1.0378873264641757 0.47445296779261015 ent_in: 0.07939446125663695 0.18074320696854426\n",
      "MI_OOD: 0.09729766653125112 0.05378489374348514 ent_in: 0.005313429113949078 0.014360897093546786\n",
      "AUPR_p: 96.51\n",
      "AUROC_p: 97.13\n",
      "AUPR_entropy: 96.96\n",
      "AUROC_entropy: 97.38\n",
      "AUPR_MI: 97.37\n",
      "AUROC_MI: 97.65\n",
      "############################################\n",
      "time 53400 66244.38680768013 test accuracy:  0.9919 0.9904\n",
      "maxp_OOD: 0.014565217391304348 0.6196267669813124 0.20629885590230956\n",
      "maxp_inD: 0.7711 0.9788582472362368 0.06670906734670656\n",
      "ent_OOD: 1.0490493828936083 0.47179764640953564 ent_in: 0.08229099088884477 0.18237507107207446\n",
      "MI_OOD: 0.09852289845106373 0.05310660270506373 ent_in: 0.0049904024070107165 0.013300646623032276\n",
      "AUPR_p: 96.62\n",
      "AUROC_p: 97.21\n",
      "AUPR_entropy: 97.04\n",
      "AUROC_entropy: 97.44\n",
      "AUPR_MI: 97.78\n",
      "AUROC_MI: 97.99\n",
      "############################################\n",
      "time 54000 66858.53484797478 test accuracy:  0.993 0.9905\n",
      "maxp_OOD: 0.015978260869565216 0.6187491583443985 0.2064970867511874\n",
      "maxp_inD: 0.759 0.9780111911838377 0.0683120341529181\n",
      "ent_OOD: 1.0540999132731974 0.47377475039235695 ent_in: 0.08600923392530874 0.1871392860602309\n",
      "MI_OOD: 0.10465043759473013 0.05626252280271173 ent_in: 0.005403436824497268 0.014133706301456222\n",
      "AUPR_p: 96.49\n",
      "AUROC_p: 97.09\n",
      "AUPR_entropy: 96.87\n",
      "AUROC_entropy: 97.32\n",
      "AUPR_MI: 97.77\n",
      "AUROC_MI: 97.97\n",
      "############################################\n",
      "time 54600 67468.97309064865 test accuracy:  0.9923 0.9892\n",
      "maxp_OOD: 0.015434782608695652 0.6154303328099026 0.20599188643399047\n",
      "maxp_inD: 0.7694 0.9787554574120789 0.0676969973731503\n",
      "ent_OOD: 1.0613096631582464 0.4720457949055463 ent_in: 0.08253793671718519 0.184172668161403\n",
      "MI_OOD: 0.11008123306021433 0.0609010087281566 ent_in: 0.005115883764549876 0.013660219256387683\n",
      "AUPR_p: 96.63\n",
      "AUROC_p: 97.26\n",
      "AUPR_entropy: 97.07\n",
      "AUROC_entropy: 97.49\n",
      "AUPR_MI: 97.96\n",
      "AUROC_MI: 98.1\n",
      "############################################\n",
      "time 55200 68076.79180169106 test accuracy:  0.9925 0.9915\n",
      "maxp_OOD: 0.017282608695652173 0.6256394358481131 0.20769003984472006\n",
      "maxp_inD: 0.7734 0.9788874790934972 0.06706562462751499\n",
      "ent_OOD: 1.0362048008429334 0.47616106338526304 ent_in: 0.0820153424768762 0.18342672024542173\n",
      "MI_OOD: 0.08851528397276294 0.049436226164692475 ent_in: 0.005110180147908122 0.013974644766789758\n",
      "AUPR_p: 96.44\n",
      "AUROC_p: 97.05\n",
      "AUPR_entropy: 96.85\n",
      "AUROC_entropy: 97.28\n",
      "AUPR_MI: 97.06\n",
      "AUROC_MI: 97.51\n",
      "############################################\n",
      "time 55800 68669.09943175316 test accuracy:  0.9924 0.9907\n",
      "maxp_OOD: 0.01576086956521739 0.6215023392992873 0.20664877272053625\n",
      "maxp_inD: 0.7743 0.9789169194869821 0.06716880241857472\n",
      "ent_OOD: 1.045882281042438 0.47323832149573286 ent_in: 0.08195681840292736 0.18372351284435742\n",
      "MI_OOD: 0.100779269368643 0.05478286684030352 ent_in: 0.00510159203708046 0.013909512422826155\n",
      "AUPR_p: 96.55\n",
      "AUROC_p: 97.17\n",
      "AUPR_entropy: 96.95\n",
      "AUROC_entropy: 97.39\n",
      "AUPR_MI: 97.72\n",
      "AUROC_MI: 97.97\n",
      "############################################\n",
      "time 56400 69275.55168366432 test accuracy:  0.9928 0.9907\n",
      "maxp_OOD: 0.01576086956521739 0.6200739037427171 0.20651318966928778\n",
      "maxp_inD: 0.7638 0.9784212459258239 0.06736415526667075\n",
      "ent_OOD: 1.0492557490172068 0.4720119574152803 ent_in: 0.08431045009226013 0.18454750699286152\n",
      "MI_OOD: 0.10639951163308632 0.05898946113070611 ent_in: 0.005888488302445577 0.015106032304234062\n",
      "AUPR_p: 96.54\n",
      "AUROC_p: 97.14\n",
      "AUPR_entropy: 96.94\n",
      "AUROC_entropy: 97.36\n",
      "AUPR_MI: 97.5\n",
      "AUROC_MI: 97.73\n",
      "############################################\n",
      "time 57000 69877.91600489616 test accuracy:  0.9928 0.9922\n",
      "maxp_OOD: 0.01717391304347826 0.6219570620282371 0.20616623562095523\n",
      "maxp_inD: 0.7639 0.9783205014899249 0.06800170291596218\n",
      "ent_OOD: 1.0447887541580583 0.4721617990292559 ent_in: 0.08431974713352795 0.18596709826875168\n",
      "MI_OOD: 0.09894173083141937 0.05334084502738397 ent_in: 0.005764310428400038 0.015187773239865893\n",
      "AUPR_p: 96.45\n",
      "AUROC_p: 97.07\n",
      "AUPR_entropy: 96.85\n",
      "AUROC_entropy: 97.3\n",
      "AUPR_MI: 97.3\n",
      "AUROC_MI: 97.65\n",
      "############################################\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "class VariationalDense:\n",
    "    \"\"\"Variational Dense Layer Class\"\"\"\n",
    "    def __init__(self, n_in, n_out, model_prob, model_lam):\n",
    "        self.model_prob = model_prob\n",
    "        self.model_lam = model_lam\n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "        self.model_M = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.01))\n",
    "        self.model_m = tf.Variable(tf.zeros([n_out]))\n",
    "        self.model_W = tf.matmul(\n",
    "            tf.diag(self.model_bern.sample((n_in, ))), self.model_M\n",
    "        )\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        output = activation(tf.matmul(X, self.model_W) + self.model_m)\n",
    "        if self.model_M.shape[1] == 1:\n",
    "            output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def regularization(self):\n",
    "        return self.model_lam * (\n",
    "            self.model_prob * tf.reduce_sum(tf.square(self.model_M)) +\n",
    "            tf.reduce_sum(tf.square(self.model_m))\n",
    "        )\n",
    "\n",
    "# Create the TensorFlow model.\n",
    "model_prob = 0.5\n",
    "model_lam = 1e-2\n",
    "\n",
    "model_X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "model_y = tf.placeholder(tf.float32, [None,10])\n",
    "b = tf.placeholder(tf.bool,shape=(),name='b')\n",
    "learning_rate = tf.placeholder(tf.float32,shape=(),name='learning_rate')\n",
    "\n",
    "w_conv1 = tf.get_variable('w_conv1', [5,5, 1,32], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w_conv2 = tf.get_variable('w_conv2', [5,5,32,64], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w0 = tf.get_variable('w_fc1', [7*7*64, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b0 = tf.get_variable('b_fc1', [1,512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w1 = tf.get_variable('w_fc2', [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.get_variable('b_fc2', [1,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# network\n",
    "con1 = tf.nn.conv2d(model_X, w_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(tf.layers.batch_normalization(con1, training=b))\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "con2 = tf.nn.conv2d(h_pool1, w_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv2 = tf.nn.relu(tf.layers.batch_normalization(con2, training=b))\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "h_pool2_flat = tf.layers.flatten(h_pool2)\n",
    "\n",
    "model_L_1 = VariationalDense(7*7*64, 512, model_prob, model_lam)\n",
    "model_out_1 = model_L_1(h_pool2_flat, tf.nn.relu)\n",
    "#h = tf.nn.relu(tf.matmul(h_pool2_flat, w0) + b0)\n",
    "#h = tf.nn.dropout(h,rate = 0)\n",
    "logits = tf.matmul(model_out_1, w1) + b1\n",
    "softmax = tf.nn.softmax(logits)\n",
    "cross_ent = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=model_y))\n",
    "correct_pred = tf.equal(tf.argmax(softmax,1), tf.argmax(model_y,1))\n",
    "accu = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "model_loss = (\n",
    "    cross_ent +\n",
    "    model_L_1.regularization +\n",
    "    #tf.reduce_sum(tf.square(w_conv1)) +\n",
    "    #tf.reduce_sum(tf.square(w_conv2)) +\n",
    "    tf.reduce_sum(tf.square(w1))*model_lam  +\n",
    "    tf.reduce_sum(tf.square(b1))*model_lam \n",
    ")\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\n",
    "saver = tf.train.Saver(max_to_keep = 200)\n",
    "M = 100\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    save_path = saver.restore(sess, \"./MC_dropout/classification_mnist12/model.ckpt\")\n",
    "    model_id = 13\n",
    "    n_ood=9200\n",
    "    n_in=10000\n",
    "    for i in range(60000):\n",
    "        if i % 600 == 0 and i!=0:\n",
    "            # Sample from the posterior.\n",
    "            n_post = 30\n",
    "            Y_post = np.zeros((n_post, n_in,10))\n",
    "            for j in range(n_post):\n",
    "                Y_post[j] = sess.run(softmax, {model_X: np.reshape(mnist.test.images[:n_in],[n_in,28,28,1]),b:False})\n",
    "            softmax1 = np.mean(Y_post,0)\n",
    "            accuracy = np.mean(np.argmax(softmax1,1)==np.argmax(mnist.test.labels[:n_in],1))\n",
    "            ac = sess.run(accu, {model_X: np.reshape(mnist.test.images[:n_in],[n_in,28,28,1]),model_y: mnist.test.labels[:n_in],b:False})\n",
    "            maxp_in = np.max(softmax1,1)\n",
    "            ent_in = np.sum(-np.log(softmax1+1e-10)*softmax1,1)\n",
    "            Eent_in = np.mean(np.sum(-np.log(Y_post+1e-10)*Y_post,2),0)\n",
    "            MI_in = ent_in - Eent_in\n",
    "            print(\"time\",i,time.time() - start_time,\"test accuracy: \",accuracy,ac)\n",
    "            \n",
    "            Y_post_OOD = np.zeros((n_post, n_ood,10))\n",
    "            for k in range(n_post):\n",
    "                Y_post_OOD[k] = sess.run(softmax, {model_X: np.reshape(safe_images[:n_ood],[n_ood,28,28,1]),b:False})\n",
    "            softmax1_OOD = np.mean(Y_post_OOD,0)\n",
    "            maxp_OOD = np.max(softmax1_OOD,1)\n",
    "            ent_OOD = np.sum(-np.log(softmax1_OOD+1e-10)*softmax1_OOD,1)\n",
    "            Eent_OOD = np.mean(np.sum(-np.log(Y_post_OOD+1e-10)*Y_post_OOD,2),0)\n",
    "            MI_OOD = ent_OOD - Eent_OOD\n",
    "            \n",
    "            print(\"maxp_OOD:\",np.mean(maxp_OOD>0.99),np.mean(maxp_OOD),np.std(maxp_OOD))\n",
    "            print(\"maxp_inD:\",np.mean(maxp_in>0.99),np.mean(maxp_in),np.std(maxp_in))\n",
    "            print(\"ent_OOD:\",np.mean(ent_OOD),np.std(ent_OOD), \"ent_in:\", np.mean(ent_in),np.std(ent_in))\n",
    "            print(\"MI_OOD:\",np.mean(MI_OOD),np.std(MI_OOD), \"ent_in:\", np.mean(MI_in),np.std(MI_in))\n",
    "\n",
    "            safe, risky  = -np.reshape(maxp_in,[n_in,1]), -np.reshape(maxp_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_p:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_p:', round(100*roc_auc_score(labels, examples), 2))\n",
    "\n",
    "            safe, risky = np.reshape(ent_in,[n_in,1]), np.reshape(ent_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_entropy:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_entropy:', round(100*roc_auc_score(labels, examples), 2))\n",
    "\n",
    "            safe, risky = np.reshape(MI_in,[n_in,1]), np.reshape(MI_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_MI:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_MI:', round(100*roc_auc_score(labels, examples), 2))\n",
    "            print(\"############################################\")\n",
    "            \n",
    "        if i < 1000:\n",
    "            a = 0.0005\n",
    "        elif i < 5000:\n",
    "            a = 0.0001\n",
    "        elif i < 20000:\n",
    "            a = 0.00005\n",
    "        elif i < 30000:\n",
    "            a = 0.00002\n",
    "        elif i < 40000:\n",
    "            a = 0.000007\n",
    "        else:\n",
    "            a = 0.000002\n",
    "        batch = mnist.train.next_batch(M)\n",
    "        x_batch = np.reshape(batch[0],[M, 28, 28, 1])\n",
    "        y_batch = batch[1]\n",
    "        sess.run(train_step, {model_X: x_batch, model_y: y_batch,learning_rate:a,b:True})\n",
    "        #sess.run(train_step, {model_X: x_batch, model_y: y_batch,learning_rate:a,b:True})\n",
    "        if i%600==0:\n",
    "            save_path = saver.save(sess, \"./MC_dropout/classification_mnist%s/model.ckpt\" % model_id)\n",
    "            model_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_post):\n",
    "    plt.plot(X_pred[:, 0], Y_post[i], \"b-\", alpha=1. / 20)\n",
    "plt.plot(X[:, 0], y, \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0 0.1832141876220703\n",
      "time 0 193.54930996894836 test accuracy:  0.1135 0.1135\n",
      "maxp_OOD: 0.0 0.161188765115712 0.002115583916352732\n",
      "maxp_inD: 0.0 0.16708447388415537 0.0006722887251578395\n",
      "ent_OOD: 2.2270380772048393 0.002131094365384566 ent_in: 2.2314331284154383 0.0006610722271097039\n",
      "MI_OOD: 0.0010294672298998327 8.215642905943005e-05 ent_in: 5.8170274950866044e-05 1.465873691605563e-05\n",
      "AUPR_p: 99.57\n",
      "AUROC_p: 99.41\n",
      "AUPR_entropy: 29.29\n",
      "AUROC_entropy: 2.08\n",
      "AUPR_MI: 100.0\n",
      "AUROC_MI: 100.0\n",
      "############################################\n",
      "time 1 347.7900550365448\n",
      "time 2 348.20240211486816\n",
      "time 3 348.65803503990173\n",
      "time 4 349.08666825294495\n",
      "time 5 349.5313632488251\n",
      "time 6 349.96964716911316\n",
      "time 7 350.39642906188965\n",
      "time 8 350.82973289489746\n",
      "time 9 351.3203909397125\n",
      "time 10 351.75177025794983\n",
      "time 11 352.1890802383423\n",
      "time 12 352.61241912841797\n",
      "time 13 353.03189420700073\n",
      "time 14 353.4659671783447\n",
      "time 15 353.8830711841583\n",
      "time 16 354.29888105392456\n",
      "time 17 354.72468304634094\n",
      "time 18 355.1363191604614\n",
      "time 19 355.56346702575684\n",
      "time 20 355.99225401878357\n",
      "time 21 356.41191005706787\n",
      "time 22 356.84759521484375\n",
      "time 23 357.25942826271057\n",
      "time 24 357.7194981575012\n",
      "time 25 358.13017201423645\n",
      "time 26 358.55265712738037\n",
      "time 27 358.96677112579346\n",
      "time 28 359.38123393058777\n",
      "time 29 359.8088479042053\n",
      "time 30 360.2362720966339\n",
      "time 31 360.6626949310303\n",
      "time 32 361.08922600746155\n",
      "time 33 361.51908898353577\n",
      "time 34 361.9407000541687\n",
      "time 35 362.3749849796295\n",
      "time 36 362.7939431667328\n",
      "time 37 363.24494314193726\n",
      "time 38 363.6614601612091\n",
      "time 39 364.0876109600067\n",
      "time 40 364.5245940685272\n",
      "time 41 364.94694995880127\n",
      "time 42 365.3780801296234\n",
      "time 43 365.8028841018677\n",
      "time 44 366.24191427230835\n",
      "time 45 366.6707489490509\n",
      "time 46 367.0899999141693\n",
      "time 47 367.5079770088196\n",
      "time 48 367.93265533447266\n",
      "time 49 368.35919713974\n",
      "time 50 368.8011269569397\n",
      "time 51 369.2077913284302\n",
      "time 52 369.64299392700195\n",
      "time 53 370.05942010879517\n",
      "time 54 370.4765272140503\n",
      "time 55 370.89698791503906\n",
      "time 56 371.3115222454071\n",
      "time 57 371.73024916648865\n",
      "time 58 372.1467411518097\n",
      "time 59 372.587256193161\n",
      "time 60 373.0064740180969\n",
      "time 61 373.44043016433716\n",
      "time 62 373.88367795944214\n",
      "time 63 374.296679019928\n",
      "time 64 374.71371126174927\n",
      "time 65 375.13771295547485\n",
      "time 66 375.5551071166992\n",
      "time 67 375.9811179637909\n",
      "time 68 376.3975441455841\n",
      "time 69 376.8257451057434\n",
      "time 70 377.2507972717285\n",
      "time 71 377.67124795913696\n",
      "time 72 378.09238505363464\n",
      "time 73 378.503849029541\n",
      "time 74 378.9321391582489\n",
      "time 75 379.34535098075867\n",
      "time 76 379.76455521583557\n",
      "time 77 380.192743062973\n",
      "time 78 380.616090297699\n",
      "time 79 381.0612120628357\n",
      "time 80 381.49257612228394\n",
      "time 81 381.9106602668762\n",
      "time 82 382.3406012058258\n",
      "time 83 382.7559380531311\n",
      "time 84 383.17849016189575\n",
      "time 85 383.6146502494812\n",
      "time 86 384.0410282611847\n",
      "time 87 384.45872807502747\n",
      "time 88 384.88953709602356\n",
      "time 89 385.3118360042572\n",
      "time 90 385.7369632720947\n",
      "time 91 386.1565670967102\n",
      "time 92 386.57676911354065\n",
      "time 93 387.0040981769562\n",
      "time 94 387.4250111579895\n",
      "time 95 387.86816811561584\n",
      "time 96 388.2845470905304\n",
      "time 97 388.7032380104065\n",
      "time 98 389.12490820884705\n",
      "time 99 389.5457899570465\n",
      "time 100 389.9621891975403\n",
      "time 101 390.3814082145691\n",
      "time 102 390.81559205055237\n",
      "time 103 391.25017404556274\n",
      "time 104 391.6674189567566\n",
      "time 105 392.09600019454956\n",
      "time 106 392.5103030204773\n",
      "time 107 392.94769310951233\n",
      "time 108 393.36679911613464\n",
      "time 109 393.80022501945496\n",
      "time 110 394.227420091629\n",
      "time 111 394.66821098327637\n",
      "time 112 395.09389901161194\n",
      "time 113 395.5134029388428\n",
      "time 114 395.9321880340576\n",
      "time 115 396.35326504707336\n",
      "time 116 396.7843191623688\n",
      "time 117 397.2060670852661\n",
      "time 118 397.6521019935608\n",
      "time 119 398.06562304496765\n",
      "time 120 398.49636006355286\n",
      "time 121 398.90348505973816\n",
      "time 122 399.3246490955353\n",
      "time 123 399.74976897239685\n",
      "time 124 400.16100001335144\n",
      "time 125 400.5856511592865\n",
      "time 126 401.0061390399933\n",
      "time 127 401.4341461658478\n",
      "time 128 401.85968708992004\n",
      "time 129 402.29286217689514\n",
      "time 130 402.7048201560974\n",
      "time 131 403.12148118019104\n",
      "time 132 403.5568232536316\n",
      "time 133 403.987685918808\n",
      "time 134 404.4062910079956\n",
      "time 135 404.8435699939728\n",
      "time 136 405.26506209373474\n",
      "time 137 405.6816611289978\n",
      "time 138 406.10141491889954\n",
      "time 139 406.5174129009247\n",
      "time 140 406.9561400413513\n",
      "time 141 407.38978099823\n",
      "time 142 407.81843614578247\n",
      "time 143 408.2470350265503\n",
      "time 144 408.6698739528656\n",
      "time 145 409.0898461341858\n",
      "time 146 409.51124906539917\n",
      "time 147 409.95049500465393\n",
      "time 148 410.38960313796997\n",
      "time 149 410.8120560646057\n",
      "time 150 411.23786211013794\n",
      "time 151 411.6861152648926\n",
      "time 152 412.127690076828\n",
      "time 153 412.5486469268799\n",
      "time 154 412.9689910411835\n",
      "time 155 413.4065771102905\n",
      "time 156 413.85044407844543\n",
      "time 157 414.27187418937683\n",
      "time 158 414.6989200115204\n",
      "time 159 415.11655616760254\n",
      "time 160 415.5448839664459\n",
      "time 161 415.9567151069641\n",
      "time 162 416.3838560581207\n",
      "time 163 416.80197525024414\n",
      "time 164 417.2207922935486\n",
      "time 165 417.6913471221924\n",
      "time 166 418.1105422973633\n",
      "time 167 418.5397992134094\n",
      "time 168 418.96417903900146\n",
      "time 169 419.38076305389404\n",
      "time 170 419.8058741092682\n",
      "time 171 420.2276830673218\n",
      "time 172 420.65482926368713\n",
      "time 173 421.11198115348816\n",
      "time 174 421.5863661766052\n",
      "time 175 422.0256772041321\n",
      "time 176 422.4484372138977\n",
      "time 177 422.877836227417\n",
      "time 178 423.32895493507385\n",
      "time 179 423.7641592025757\n",
      "time 180 424.21358013153076\n",
      "time 181 424.63656210899353\n",
      "time 182 425.0757451057434\n",
      "time 183 425.5096158981323\n",
      "time 184 425.9494740962982\n",
      "time 185 426.3856201171875\n",
      "time 186 426.81690192222595\n",
      "time 187 427.2538261413574\n",
      "time 188 427.6891191005707\n",
      "time 189 428.1060240268707\n",
      "time 190 428.5403480529785\n",
      "time 191 428.97930812835693\n",
      "time 192 429.40940713882446\n",
      "time 193 429.84041810035706\n",
      "time 194 430.35515117645264\n",
      "time 195 430.969407081604\n",
      "time 196 431.5083920955658\n",
      "time 197 431.9593880176544\n",
      "time 198 432.4240472316742\n",
      "time 199 432.9534590244293\n",
      "time 200 433.4474971294403\n",
      "time 201 433.925466299057\n",
      "time 202 434.35154700279236\n",
      "time 203 434.8237361907959\n",
      "time 204 435.3049020767212\n",
      "time 205 435.76850628852844\n",
      "time 206 436.2301971912384\n",
      "time 207 436.7439920902252\n",
      "time 208 437.2240378856659\n",
      "time 209 437.6567771434784\n",
      "time 210 438.12705421447754\n",
      "time 211 438.62376403808594\n",
      "time 212 439.05940103530884\n",
      "time 213 439.5294690132141\n",
      "time 214 440.0484721660614\n",
      "time 215 440.5207371711731\n",
      "time 216 440.98984813690186\n",
      "time 217 441.4751989841461\n",
      "time 218 441.89930605888367\n",
      "time 219 442.3624572753906\n",
      "time 220 442.81904315948486\n",
      "time 221 443.3486931324005\n",
      "time 222 443.7953281402588\n",
      "time 223 444.2932391166687\n",
      "time 224 444.83629322052\n",
      "time 225 445.3602890968323\n",
      "time 226 445.895161151886\n",
      "time 227 446.42747020721436\n",
      "time 228 446.86976528167725\n",
      "time 229 447.30703806877136\n",
      "time 230 447.7789080142975\n",
      "time 231 448.2155091762543\n",
      "time 232 448.66170620918274\n",
      "time 233 449.0815351009369\n",
      "time 234 449.5050718784332\n",
      "time 235 449.9469051361084\n",
      "time 236 450.37557721138\n",
      "time 237 450.7880582809448\n",
      "time 238 451.2097113132477\n",
      "time 239 451.6330850124359\n",
      "time 240 452.0504641532898\n",
      "time 241 452.50792717933655\n",
      "time 242 452.9577660560608\n",
      "time 243 453.38961911201477\n",
      "time 244 453.8542261123657\n",
      "time 245 454.2941310405731\n",
      "time 246 454.77796626091003\n",
      "time 247 455.2388741970062\n",
      "time 248 455.9096100330353\n",
      "time 249 456.4271590709686\n",
      "time 250 456.9691479206085\n",
      "time 251 457.51261496543884\n",
      "time 252 458.01125717163086\n",
      "time 253 458.5109021663666\n",
      "time 254 459.0087912082672\n",
      "time 255 459.507364988327\n",
      "time 256 460.0082252025604\n",
      "time 257 460.5241611003876\n",
      "time 258 461.0147020816803\n",
      "time 259 461.6216230392456\n",
      "time 260 462.15545105934143\n",
      "time 261 462.58498311042786\n",
      "time 262 463.01534605026245\n",
      "time 263 463.53228211402893\n",
      "time 264 464.1875550746918\n",
      "time 265 464.6374342441559\n",
      "time 266 465.2238721847534\n",
      "time 267 465.6978540420532\n",
      "time 268 466.21635007858276\n",
      "time 269 466.6832721233368\n",
      "time 270 467.1260621547699\n",
      "time 271 467.7506902217865\n",
      "time 272 468.32983922958374\n",
      "time 273 468.8034839630127\n",
      "time 274 469.3965902328491\n",
      "time 275 469.848069190979\n",
      "time 276 470.28413820266724\n",
      "time 277 470.7620460987091\n",
      "time 278 471.31702995300293\n",
      "time 279 471.9361870288849\n",
      "time 280 472.4004020690918\n",
      "time 281 472.8393700122833\n",
      "time 282 473.2923080921173\n",
      "time 283 473.7359850406647\n",
      "time 284 474.1980490684509\n",
      "time 285 474.63753032684326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 286 475.10084319114685\n",
      "time 287 475.54856419563293\n",
      "time 288 476.0035631656647\n",
      "time 289 476.4983739852905\n",
      "time 290 476.9546172618866\n",
      "time 291 477.3976490497589\n",
      "time 292 477.85429215431213\n",
      "time 293 478.30073404312134\n",
      "time 294 478.7273921966553\n",
      "time 295 479.177285194397\n",
      "time 296 479.6380281448364\n",
      "time 297 480.0735282897949\n",
      "time 298 480.50767493247986\n",
      "time 299 480.97645115852356\n",
      "time 300 481.4064130783081\n",
      "time 301 481.82094717025757\n",
      "time 302 482.2717831134796\n",
      "time 303 482.72282123565674\n",
      "time 304 483.1615822315216\n",
      "time 305 483.58195304870605\n",
      "time 306 484.0386309623718\n",
      "time 307 484.5109372138977\n",
      "time 308 484.9506571292877\n",
      "time 309 485.3903241157532\n",
      "time 310 485.8228681087494\n",
      "time 311 486.26952505111694\n",
      "time 312 486.7423839569092\n",
      "time 313 487.18880796432495\n",
      "time 314 487.6098072528839\n",
      "time 315 488.05074310302734\n",
      "time 316 488.50521087646484\n",
      "time 317 488.95733404159546\n",
      "time 318 489.4279692173004\n",
      "time 319 489.8761339187622\n",
      "time 320 490.3028521537781\n",
      "time 321 490.7484350204468\n",
      "time 322 491.2207021713257\n",
      "time 323 491.66577315330505\n",
      "time 324 492.09304308891296\n",
      "time 325 492.5333032608032\n",
      "time 326 492.9986572265625\n",
      "time 327 493.4349501132965\n",
      "time 328 493.8771159648895\n",
      "time 329 494.3143210411072\n",
      "time 330 494.7349741458893\n",
      "time 331 495.15581607818604\n",
      "time 332 495.59032917022705\n",
      "time 333 496.0898141860962\n",
      "time 334 496.60265707969666\n",
      "time 335 497.0550322532654\n",
      "time 336 497.50709104537964\n",
      "time 337 497.9415822029114\n",
      "time 338 498.3640751838684\n",
      "time 339 498.78467202186584\n",
      "time 340 499.2040650844574\n",
      "time 341 499.6170482635498\n",
      "time 342 500.04949831962585\n",
      "time 343 500.50710105895996\n",
      "time 344 501.0673899650574\n",
      "time 345 501.62650203704834\n",
      "time 346 502.1336410045624\n",
      "time 347 502.57141304016113\n",
      "time 348 502.9964859485626\n",
      "time 349 503.4789650440216\n",
      "time 350 503.9925651550293\n",
      "time 351 504.4277410507202\n",
      "time 352 504.8583791255951\n",
      "time 353 505.2876341342926\n",
      "time 354 505.72634410858154\n",
      "time 355 506.15413308143616\n",
      "time 356 506.59038400650024\n",
      "time 357 507.0135760307312\n",
      "time 358 507.4390962123871\n",
      "time 359 507.88288593292236\n",
      "time 360 508.3124260902405\n",
      "time 361 508.742388010025\n",
      "time 362 509.16093707084656\n",
      "time 363 509.5758023262024\n",
      "time 364 509.99673295021057\n",
      "time 365 510.41831827163696\n",
      "time 366 510.88493514060974\n",
      "time 367 511.35788011550903\n",
      "time 368 511.8520610332489\n",
      "time 369 512.2618291378021\n",
      "time 370 512.6754472255707\n",
      "time 371 513.1048991680145\n",
      "time 372 513.5220742225647\n",
      "time 373 513.9508061408997\n",
      "time 374 514.3770980834961\n",
      "time 375 514.8101263046265\n",
      "time 376 515.2586250305176\n",
      "time 377 515.6944670677185\n",
      "time 378 516.1118280887604\n",
      "time 379 516.5377271175385\n",
      "time 380 516.9577641487122\n",
      "time 381 517.3935601711273\n",
      "time 382 517.8351140022278\n",
      "time 383 518.2564661502838\n",
      "time 384 518.6796259880066\n",
      "time 385 519.1087861061096\n",
      "time 386 519.5263350009918\n",
      "time 387 519.956826210022\n",
      "time 388 520.3780291080475\n",
      "time 389 520.8081879615784\n",
      "time 390 521.2353632450104\n",
      "time 391 521.6934762001038\n",
      "time 392 522.126100063324\n",
      "time 393 522.5748710632324\n",
      "time 394 523.0034561157227\n",
      "time 395 523.4217150211334\n",
      "time 396 523.873456954956\n",
      "time 397 524.3229179382324\n",
      "time 398 524.7960112094879\n",
      "time 399 525.2236120700836\n",
      "time 400 525.6677091121674\n",
      "time 401 526.1089820861816\n",
      "time 402 526.5434992313385\n",
      "time 403 526.973423242569\n",
      "time 404 527.4071431159973\n",
      "time 405 527.8562650680542\n",
      "time 406 528.3036761283875\n",
      "time 407 528.7442951202393\n",
      "time 408 529.1763160228729\n",
      "time 409 529.6388511657715\n",
      "time 410 530.0840809345245\n",
      "time 411 530.5594470500946\n",
      "time 412 531.0285441875458\n",
      "time 413 531.4960441589355\n",
      "time 414 531.9634251594543\n",
      "time 415 532.4189419746399\n",
      "time 416 532.9068529605865\n",
      "time 417 533.3657002449036\n",
      "time 418 533.7996361255646\n",
      "time 419 534.2221291065216\n",
      "time 420 534.6680541038513\n",
      "time 421 535.1333992481232\n",
      "time 422 535.6022651195526\n",
      "time 423 536.1002283096313\n",
      "time 424 536.568922996521\n",
      "time 425 537.0213360786438\n",
      "time 426 537.5069582462311\n",
      "time 427 537.9774379730225\n",
      "time 428 538.440954208374\n",
      "time 429 538.8974370956421\n",
      "time 430 539.3328552246094\n",
      "time 431 539.7736032009125\n",
      "time 432 540.2084290981293\n",
      "time 433 540.653911113739\n",
      "time 434 541.1255280971527\n",
      "time 435 541.5656180381775\n",
      "time 436 542.046108007431\n",
      "time 437 542.4789571762085\n",
      "time 438 542.9099142551422\n",
      "time 439 543.3326051235199\n",
      "time 440 543.817419052124\n",
      "time 441 544.2401812076569\n",
      "time 442 544.6968550682068\n",
      "time 443 545.1270480155945\n",
      "time 444 545.5967969894409\n",
      "time 445 546.0679750442505\n",
      "time 446 546.518473148346\n",
      "time 447 546.9896290302277\n",
      "time 448 547.4895272254944\n",
      "time 449 547.9344351291656\n",
      "time 450 548.3605840206146\n",
      "time 451 548.7905731201172\n",
      "time 452 549.2253022193909\n",
      "time 453 549.649199962616\n",
      "time 454 550.1178221702576\n",
      "time 455 550.5659551620483\n",
      "time 456 551.0126721858978\n",
      "time 457 551.4310300350189\n",
      "time 458 551.8484170436859\n",
      "time 459 552.2728972434998\n",
      "time 460 552.7052249908447\n",
      "time 461 553.1361212730408\n",
      "time 462 553.5601632595062\n",
      "time 463 553.984060049057\n",
      "time 464 554.405620098114\n",
      "time 465 554.8217680454254\n",
      "time 466 555.2426261901855\n",
      "time 467 555.6636991500854\n",
      "time 468 556.0915040969849\n",
      "time 469 556.51384806633\n",
      "time 470 556.9423031806946\n",
      "time 471 557.3773140907288\n",
      "time 472 557.8241550922394\n",
      "time 473 558.2682981491089\n",
      "time 474 558.7034780979156\n",
      "time 475 559.1587431430817\n",
      "time 476 559.5795691013336\n",
      "time 477 560.0185322761536\n",
      "time 478 560.4477121829987\n",
      "time 479 560.8710663318634\n",
      "time 480 561.3570063114166\n",
      "time 481 561.9435830116272\n",
      "time 482 562.5050151348114\n",
      "time 483 562.9320330619812\n",
      "time 484 563.3803479671478\n",
      "time 485 563.8102321624756\n",
      "time 486 564.2528901100159\n",
      "time 487 564.708847284317\n",
      "time 488 565.1469352245331\n",
      "time 489 565.5986061096191\n",
      "time 490 566.0795431137085\n",
      "time 491 566.5280380249023\n",
      "time 492 566.9720590114594\n",
      "time 493 567.3982532024384\n",
      "time 494 567.8641490936279\n",
      "time 495 568.2996311187744\n",
      "time 496 568.7505440711975\n",
      "time 497 569.1953301429749\n",
      "time 498 569.6415371894836\n",
      "time 499 570.0968761444092\n",
      "time 500 570.5501420497894\n",
      "time 501 571.0001392364502\n",
      "time 502 571.4302461147308\n",
      "time 503 571.8790400028229\n",
      "time 504 572.3336782455444\n",
      "time 505 572.7845780849457\n",
      "time 506 573.2213361263275\n",
      "time 507 573.6618030071259\n",
      "time 508 574.0923080444336\n",
      "time 509 574.5297989845276\n",
      "time 510 574.9746341705322\n",
      "time 511 575.4258282184601\n",
      "time 512 575.9498980045319\n",
      "time 513 576.4433212280273\n",
      "time 514 576.9301331043243\n",
      "time 515 577.373113155365\n",
      "time 516 577.8148901462555\n",
      "time 517 578.2684350013733\n",
      "time 518 578.734884262085\n",
      "time 519 579.1989500522614\n",
      "time 520 579.6340339183807\n",
      "time 521 580.0707280635834\n",
      "time 522 580.5620560646057\n",
      "time 523 581.201446056366\n",
      "time 524 581.7689800262451\n",
      "time 525 582.3001801967621\n",
      "time 526 582.7515480518341\n",
      "time 527 583.1932511329651\n",
      "time 528 583.6218111515045\n",
      "time 529 584.0588192939758\n",
      "time 530 584.4928872585297\n",
      "time 531 584.932302236557\n",
      "time 532 585.3664631843567\n",
      "time 533 585.8106739521027\n",
      "time 534 586.282653093338\n",
      "time 535 586.7660810947418\n",
      "time 536 587.2628030776978\n",
      "time 537 587.7580261230469\n",
      "time 538 588.2486453056335\n",
      "time 539 588.7507190704346\n",
      "time 540 589.187824010849\n",
      "time 541 589.6665532588959\n",
      "time 542 590.1047141551971\n",
      "time 543 590.5862369537354\n",
      "time 544 591.0801112651825\n",
      "time 545 591.5416100025177\n",
      "time 546 592.0325911045074\n",
      "time 547 592.5488610267639\n",
      "time 548 593.0650570392609\n",
      "time 549 593.5246090888977\n",
      "time 550 594.0102150440216\n",
      "time 551 594.5181109905243\n",
      "time 552 595.0019040107727\n",
      "time 553 595.5160760879517\n",
      "time 554 595.9385652542114\n",
      "time 555 596.5251441001892\n",
      "time 556 597.223149061203\n",
      "time 557 597.7432689666748\n",
      "time 558 598.2066321372986\n",
      "time 559 598.6921548843384\n",
      "time 560 599.2601671218872\n",
      "time 561 599.7814259529114\n",
      "time 562 600.2425780296326\n",
      "time 563 600.6978821754456\n",
      "time 564 601.148029088974\n",
      "time 565 601.6184279918671\n",
      "time 566 602.0771720409393\n",
      "time 567 602.5189692974091\n",
      "time 568 602.958220243454\n",
      "time 569 603.4107999801636\n",
      "time 570 603.8479130268097\n",
      "time 571 604.281928062439\n",
      "time 572 604.714408159256\n",
      "time 573 605.1579160690308\n",
      "time 574 605.5965571403503\n",
      "time 575 606.0452260971069\n",
      "time 576 606.4913322925568\n",
      "time 577 606.9442739486694\n",
      "time 578 607.3708560466766\n",
      "time 579 607.81968998909\n",
      "time 580 608.2580320835114\n",
      "time 581 608.7081830501556\n",
      "time 582 609.1302790641785\n",
      "time 583 609.5643379688263\n",
      "time 584 609.9825003147125\n",
      "time 585 610.4079959392548\n",
      "time 586 610.8469750881195\n",
      "time 587 611.2878971099854\n",
      "time 588 611.7435522079468\n",
      "time 589 612.2085862159729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 590 612.6768300533295\n",
      "time 591 613.239953994751\n",
      "time 592 613.6859269142151\n",
      "time 593 614.1085278987885\n",
      "time 594 614.5599792003632\n",
      "time 595 615.0065271854401\n",
      "time 596 615.4373152256012\n",
      "time 597 615.8659873008728\n",
      "time 598 616.308030128479\n",
      "time 599 616.7541120052338\n",
      "time 600 617.2273459434509\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b24d337b1d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mY_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mY_post\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;31m#print(Y_post)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0msoftmax1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "tf.reset_default_graph()\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "class VariationalDense:\n",
    "    \"\"\"Variational Dense Layer Class\"\"\"\n",
    "    def __init__(self, n_in, n_out, model_prob, model_lam):\n",
    "        self.model_prob = model_prob\n",
    "        self.model_lam = model_lam\n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "        self.model_M = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.01))\n",
    "        self.model_m = tf.Variable(tf.zeros([n_out]))\n",
    "        self.model_W = tf.matmul(\n",
    "            tf.diag(self.model_bern.sample((n_in, ))), self.model_M\n",
    "        )\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        output = activation(tf.matmul(X, self.model_W) + self.model_m)\n",
    "        if self.model_M.shape[1] == 1:\n",
    "            output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def regularization(self):\n",
    "        return self.model_lam * (\n",
    "            self.model_prob * tf.reduce_sum(tf.square(self.model_M)) +\n",
    "            tf.reduce_sum(tf.square(self.model_m))\n",
    "        )\n",
    "\n",
    "# Create the TensorFlow model.\n",
    "model_prob = 0.5\n",
    "model_lam = 1e-2\n",
    "\n",
    "model_X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "model_y = tf.placeholder(tf.float32, [None,10])\n",
    "b = tf.placeholder(tf.bool,shape=(),name='b')\n",
    "learning_rate = tf.placeholder(tf.float32,shape=(),name='learning_rate')\n",
    "\n",
    "w_conv1 = tf.get_variable('w_conv1', [5,5, 1,32], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w_conv2 = tf.get_variable('w_conv2', [5,5,32,64], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w0 = tf.get_variable('w_fc1', [7*7*64, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b0 = tf.get_variable('b_fc1', [1,512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w1 = tf.get_variable('w_fc2', [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.get_variable('b_fc2', [1,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# network\n",
    "con1 = tf.nn.conv2d(model_X, w_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(tf.layers.batch_normalization(con1, training=b))\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "con2 = tf.nn.conv2d(h_pool1, w_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv2 = tf.nn.relu(tf.layers.batch_normalization(con2, training=b))\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "h_pool2_flat = tf.layers.flatten(h_pool2)\n",
    "\n",
    "model_L_1 = VariationalDense(7*7*64, 512, model_prob, model_lam)\n",
    "model_out_1 = model_L_1(h_pool2_flat, tf.nn.relu)\n",
    "#h = tf.nn.relu(tf.matmul(h_pool2_flat, w0) + b0)\n",
    "#h = tf.nn.dropout(h,rate = 0)\n",
    "logits = tf.matmul(model_out_1, w1) + b1\n",
    "softmax = tf.nn.softmax(logits)\n",
    "cross_ent = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=model_y))\n",
    "correct_pred = tf.equal(tf.argmax(softmax,1), tf.argmax(model_y,1))\n",
    "accu = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "model_loss = (\n",
    "    cross_ent +\n",
    "    model_L_1.regularization +\n",
    "    #tf.reduce_sum(tf.square(w_conv1)) +\n",
    "    #tf.reduce_sum(tf.square(w_conv2)) +\n",
    "    tf.reduce_sum(tf.square(w1))*model_lam  +\n",
    "    tf.reduce_sum(tf.square(b1))*model_lam \n",
    ")\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\n",
    "saver = tf.train.Saver(max_to_keep = 200)\n",
    "M = 100\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #save_path = saver.restore(sess, \"./MC_dropout/classification_mnist100/model.ckpt\")\n",
    "    model_id = 0\n",
    "    n_ood=9200\n",
    "    n_in=10000\n",
    "    for i in range(60000):\n",
    "        print(\"time\",i,time.time() - start_time)\n",
    "        if i % 600 == 0:\n",
    "            safe_images = np.reshape(np.random.normal(0,1,[9200*28*28]),[9200,28,28,1])\n",
    "            # Sample from the posterior.\n",
    "            n_post = 30\n",
    "            Y_post = np.zeros((n_post, n_in,10))\n",
    "            for j in range(n_post):\n",
    "                Y_post[j] = sess.run(softmax, {model_X: np.reshape(mnist.test.images[:n_in],[n_in,28,28,1]),b:False})\n",
    "            #print(Y_post)\n",
    "            softmax1 = np.mean(Y_post,0)\n",
    "            #print(\"softmax\",softmax1)\n",
    "            accuracy = np.mean(np.argmax(softmax1,1)==np.argmax(mnist.test.labels[:n_in],1))\n",
    "            ac = sess.run(accu, {model_X: np.reshape(mnist.test.images[:n_in],[n_in,28,28,1]),model_y: mnist.test.labels[:n_in],b:False})\n",
    "            maxp_in = np.max(softmax1,1)\n",
    "            ent_in = np.sum(-np.log(softmax1+1e-10)*softmax1,1)\n",
    "            Eent_in = np.mean(np.sum(-np.log(Y_post+1e-10)*Y_post,2),0)\n",
    "            MI_in = ent_in - Eent_in\n",
    "            print(\"time\",i,time.time() - start_time,\"test accuracy: \",accuracy,ac)\n",
    "            \n",
    "            Y_post_OOD = np.zeros((n_post, n_ood,10))\n",
    "            for k in range(n_post):\n",
    "                Y_post_OOD[k] = sess.run(softmax, {model_X: np.reshape(safe_images[:n_ood],[n_ood,28,28,1]),b:False})\n",
    "            softmax1_OOD = np.mean(Y_post_OOD,0)\n",
    "            maxp_OOD = np.max(softmax1_OOD,1)\n",
    "            ent_OOD = np.sum(-np.log(softmax1_OOD+1e-10)*softmax1_OOD,1)\n",
    "            Eent_OOD = np.mean(np.sum(-np.log(Y_post_OOD+1e-10)*Y_post_OOD,2),0)\n",
    "            MI_OOD = ent_OOD - Eent_OOD\n",
    "            \n",
    "            print(\"maxp_OOD:\",np.mean(maxp_OOD>0.99),np.mean(maxp_OOD),np.std(maxp_OOD))\n",
    "            print(\"maxp_inD:\",np.mean(maxp_in>0.99),np.mean(maxp_in),np.std(maxp_in))\n",
    "            print(\"ent_OOD:\",np.mean(ent_OOD),np.std(ent_OOD), \"ent_in:\", np.mean(ent_in),np.std(ent_in))\n",
    "            print(\"MI_OOD:\",np.mean(MI_OOD),np.std(MI_OOD), \"ent_in:\", np.mean(MI_in),np.std(MI_in))\n",
    "\n",
    "            safe, risky  = -np.reshape(maxp_in,[n_in,1]), -np.reshape(maxp_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_p:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_p:', round(100*roc_auc_score(labels, examples), 2))\n",
    "\n",
    "            safe, risky = np.reshape(ent_in,[n_in,1]), np.reshape(ent_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_entropy:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_entropy:', round(100*roc_auc_score(labels, examples), 2))\n",
    "\n",
    "            safe, risky = np.reshape(MI_in,[n_in,1]), np.reshape(MI_OOD,[n_ood,1])\n",
    "            labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "            labels[safe.shape[0]:] += 1\n",
    "            examples = np.squeeze(np.vstack((safe, risky)))\n",
    "            print('AUPR_MI:', round(100*average_precision_score(labels, examples), 2))\n",
    "            print('AUROC_MI:', round(100*roc_auc_score(labels, examples), 2))\n",
    "            print(\"############################################\")\n",
    "            \n",
    "        if i < 1000:\n",
    "            a = 0.0005\n",
    "        elif i < 5000:\n",
    "            a = 0.0001\n",
    "        elif i < 20000:\n",
    "            a = 0.00005\n",
    "        elif i < 30000:\n",
    "            a = 0.00002\n",
    "        elif i < 40000:\n",
    "            a = 0.000007\n",
    "        else:\n",
    "            a = 0.000002\n",
    "        batch = mnist.train.next_batch(M)\n",
    "        x_batch = np.reshape(batch[0],[M, 28, 28, 1])\n",
    "        y_batch = batch[1]\n",
    "        sess.run(train_step, {model_X: x_batch, model_y: y_batch,learning_rate:a,b:True})\n",
    "        #sess.run(train_step, {model_X: x_batch, model_y: y_batch,learning_rate:a,b:True})\n",
    "        if i%600==0:\n",
    "            save_path = saver.save(sess, \"./MC_dropout/classification_mnist%s/model.ckpt\" % model_id)\n",
    "            model_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_batch[0].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXmYVMX1/t/ZV2ZggNnYQ0AEVEBEMBhHjSI4CRh/FBA1KgT0ETAa4kbUYNwwuAQNkYCiGDcKwX1Bg/uGAoliRBAREUEUXED2gfn+Mc216nbfUy0DM+Ov3s/z+Fin3znVNXf60PfWck5KdXU1CCH+kVrfAyCE1A8MfkI8hcFPiKcw+AnxFAY/IZ7C4CfEUxj8hHgKg58QT2HwE+Ip6XX8ftxOSMiBJyWZH6pV8CulTgIwGUAagDu01hNdPt27dw/a9913H0477bTAbt26teh79tlnR2rvv/++6Jufny/qI0eOtOysrCzs2LEjsKdMmRLp26NHD7HvDz/8UNTfe+89Ud+4cWPQvuaaa3D55Zdbetu2bSN9O3fuLPb9xRdfiPquXbtEvbS0NGiffPLJePLJJy19xowZkb5jx44V+x49erSoX3vttaJu/s1PPPFEPPvss4H98ccfi77NmzcX9dRU+aZ5xYoVor59+/agfeGFF+KWW24J7IKCAtF36dKlkdqsWbNEX5N9vu1XSqUBmAKgP4DOAIYppeRPGiGkwVCbZ/5eAFZorVdqrXcCeBDAwP0zLELIgSZlX0/1KaX+H4CTtNa/i9lnADhSaz0m9HOjAIwCAK314ebtebt27azbr8zMTPE9mzZtGqmZt1GJcN2mhW/zUlJSYF4b6fY4NzdX7Nt8fEjEtm3bRL2qqipot2jRAp999pmlS9ctJydH7Nt1W+/6fGRkZATtwsJCfPvtt5a+YcOGSN/i4mKx79WrV4t6ixYtRD0tLS1oFxQUYNOmTYHt+pukp8tPxCkp8mO16/NoXteSkhKsX78+sM1xJ0L6vLRv3x6og2f+RG8Q90nRWk8DMG2vbj7j/5ie+e+9995IXz7z18Bn/u/5//qZH8AaAK0MuyWAtbXojxBSh9Tmm/9tAB2UUu0AfAZgKIDf7JdREUIOOPsc/FrrKqXUGADzULPUN0Nr/T+X39ChQ4N2kyZN4mwJ89YoTO/evUVf8/Y0EW+99ZZl9+jRA4sXLw7siy66KNI3/Awe5rvvvhP1N954Q9T79OkTtPPy8iwbAJ566qlI3/LycrHvNWvWiHq3bt1E/ZBDDgnaubm5OPTQQy39lFNOifQNzw+EueKKK0T9rrvuEvVBgwYF7Z07d+LTTz8N7DZt2oi+TzzxhKhXVFSIuvR5AYDly5cH7SZNmmDIkCGBfc4554i+v/vd70Q9WWq1zq+1fgpA9CePENJg4fZeQjyFwU+IpzD4CfEUBj8hnsLgJ8RTGPyEeEpdn+fHO++8E7S3bdtm2eZaZyKktVlz33YiXFtsw2vOnTp1stb5J02aFOlrrh8n4le/+pWou7aKLliwIGhXVVXFbcmV9ke4tjW79qC/9tprov7mm28G7UsuuQTTp0+3dGmfuutMhGvsBx10kKjPnTs3aFdWVlr2lVdeKfq6rovrHMqIESNEfeHChUH7iSeewODBgwM7vNU8jGsre7Lwm58QT2HwE+IpDH5CPIXBT4inMPgJ8RQGPyGeUudLfY0aNQraaWlplv3VV1+JvsOHD4/Uli1bJvq6MtqEl34GDBiAxx57LLClZcjJkyeLfb/99tui/sc//lHUzbRNe/bsiUvj9Mtf/jLS15VuauJEOeHyn/70J1Hv169f0C4sLMSAAQMsff78+ZG+mzdvFvuWjgMDwOuvvy7q5lHqzMxMtGr1fe6Z//1PPn3uWmZ0pRgLH20OY/7u2dnZ1rLlT3/6U9HXdUw7WfjNT4inMPgJ8RQGPyGewuAnxFMY/IR4CoOfEE9h8BPiKftcrmsfqVZKBcb111+Pyy67LLClclwAcNhhh0VqXbp0EX0feOABUT/hhBMsu6KiAi+++GJgf/DBB5G+WVlZYt+uqjhmqaZEmBV9Zs6ciTPPPNPSzfTZYVx7J4488khRd+0TuO+++4L2gw8+aKViB2BVZArjOjbrSiteVlYm6mYlpfDf05Vu3VWua8uWLaK+detWUTf/ZscccwxeeumlwJ43b57oK8Xs1KlTgSTLdfGbnxBPYfAT4ikMfkI8hcFPiKcw+AnxFAY/IZ7C4CfEU2p1nl8ptQrAZgC7AVRprXu6fC644IKgXVJSYtlmquxESGW2H3/8cdE3fAY+THgdv3fv3tZr0tnxxo0bi32fccYZor506VJRP+aYY4J2cXExRo8ebenvvvtupG9BQYHYtyv99dq1a0XdTFHdrFmzuJTV0nX/+9//LvYtlR4H3GW0n3322aDdo0cPy27evLnou2LFClF3pWN3+bdv3z5oZ2VlWbarVL2r72TZH8k8jtVab9gP/RBC6hDe9hPiKbUN/moAzyqlFimlRu2PARFC6oZa7e1XSpVrrdcqpYoBPAdgrNb65dDPjAIwCgC01oebedVycnKsZ0LXfuiMjIxIzbXXeteuXaKenZ1t2U2bNsXGjRsD2xx3GKkk1d6+JFx73M3+CwsL40qLSc/Vrr+vmUMxEa7rZvZfVFQUd5Zgz549kb6uMw0dOnQQ9W+++UbUq6qqgnZpaSk+//zzwHbt3d+xY4eou+Z5XH9T0z8rK8t6P9d5DGlssbmDpPb277eDPUqpCQC+01rfKPxYtTlxduihh1qTVa4Jv5YtW0ZqrmSOX375pah37NjRss866yzcfffdSfV/oCf8CgsLg3ZlZWXcRJc04ScFHwD8/Oc/F3XXhJ8ZYMOGDYs7QCX9w3TTTTeJfdd2ws/8m1966aVWstL6nvAbOHBg0G7fvj0++uijwHYdQpP61loDB/pgj1IqTynVaG8bwIkA3pO9CCENhdrM9pcAeDh2RDcdwP1a62f2y6gIIQecfQ5+rfVKANEH7CMwb9Vat25t2a5b98rKykitdevWou+gQYNE/YYbbrDswYMHW+WnL7/88khf87x9Io4++mhRX7Vqlaib16WioiLuOknzEVdccYXY9+zZs0V91qxZon7JJZcE7bS0NBQVFVm6ubYeplevXmLfDz30kKiXlJSIupnjoVGjRqioqAhsV66A5cuXi3peXp6om7kEErFkyZKgXV5ebtmuvP2uvRvJwqU+QjyFwU+IpzD4CfEUBj8hnsLgJ8RTGPyEeEqdl+ju2fP7U795eXmW3adPH9F3wYIFkZq5QyoRn3zyiaibWz+Bmm2t5mtSqmfXVtDzzz9f1J95Rt4eMWbMmKAdPv4JyLvNXLvopNTaQM3RZonnn38+aB933HF4//33Lf3YY4+N9JV2JgLuba7PPfecqB988MFB+4gjjsCjjz4a2H379hV9zZTyidi9e7eoT58+XdTN61JVVWVtdXalS3elgk8WfvMT4ikMfkI8hcFPiKcw+AnxFAY/IZ7C4CfEUxj8hHhKna/zv/DCC0G7Z8+elu0qs71y5cpI7bzzzhN9b775ZlG/6qqrLLu8vNx6bcOG6ATFubm5Yt9SaXHAnYLMLC19yimnWDYAq7xzmFatWol9L1q0SNRdKcrMtfTs7GzLBoA5c+ZE+prl2hMh+QJA//79RX3nzp1BOyMjA+Xl5YHtynDk+ry4sgi50pLn5+cH7dTUVMsuLi4WfX/xi1+IerLwm58QT2HwE+IpDH5CPIXBT4inMPgJ8RQGPyGewuAnxFPqfJ2/Xbt2QTszM9OyXVV1zNTLYVxrwi7OOeccy3788cet1/72t79F+rr2GLjWozt37izqZnmunJwcdO3a1dKlXAOuc+ebN28WdemaA8CHH34YtKurq+NyG0jlpocMGSL27Uqf7UqPffbZZwft0047DXfeeWdgX3TRRaJvv379RH3cuHGiPmDAAFGX9ke40oq7ypQlC7/5CfEUBj8hnsLgJ8RTGPyEeAqDnxBPYfAT4ikMfkI8xbnOr5SaAaASwBda666x14oAzALQFsAqAEpr/XUyb2jmJw/nKw/now8jlWReunSp6Bs+Zx5m4MCBlh0+zz9z5sxI39NPP13s27VmfM8994i6Wco6KysLbdq0sfRt27ZF+ta23LPrXPtZZ50VtNPT09G0aVNLN8/Uhxk+fLjYtytPwu233y7qf/jDH4J2SUmJZbv2CEj7EwB3TYG//OUvov7www8H7enTp1t1AgoLC0XfzMzMSM1Vj8AkmW/+uwGcFHrtUgDztdYdAMyP2YSQHxHO4Ndavwwg/M/cQAB7vwpnAhi0n8dFCDnA7Oszf4nWeh0AxP4v5x0ihDQ4Uqqrq50/pJRqC+AJ45n/G611Y0P/Wmud8CFJKTUKwCgA0Fofbu5bLi4utuqOZWVliePIyMiI1Fx71F31z7Kzsy27sLDQ2lMv7ad2jdv1DLdx40ZRz8vLC9pNmjTB11/b0yvbt2/f57G5cvSF3ytMs2bNgnajRo3i/g4u/9qMzVUj0cyL16xZMysPo3lN9+W9XWcm1q5dK+rm57FNmzZWLUnXe0uf5dgcj/xhj7GvB3vWK6XKtNbrlFJlACIrB2qtpwGYFjOrb7vttkAbO3YsTLs2E37hpJZhcnJyRL1jx46WXVlZaSVpfOSRRyJ9O3ToIPa9Pyf8lFLQWlv6Bx98EOlb2wk/c2IqEeaE33HHHWcV7gSAhx56KNI3PV3++Lkm/FatWiXq5uTXiBEjrIM9RxxxhOh7oCf8zN99+vTpGDlyZGDXZsJv7ty5oq/Jvt72PwbgzFj7TACPCj9LCGmAJLPU9wCACgDNlFJrAPwZwEQAWik1AsBqAIMP5CAJIfsfZ/BrrYdFSMfvyxuat/bhWvN9+vQRfY855phIzVVH3nWm/tNPP7XsnTt3Wq9Jz1muvPyuWzHXHgSz5v22bdssG5DnQlzPj+HHnTCu21uzZsARRxwRV0PgoIMOivRdsGCB2PfJJ58s6tLvDQBHHXVU0M7Pz7fsdevWib5t27YVdXNdPhFXXnmlqJeVlQXt1q1bW4+/d999t+jrqjmQLNzhR4inMPgJ8RQGPyGewuAnxFMY/IR4CoOfEE+p89Td06ZNC9p9+/a1bNdutMrKykjt2GOPFX2vu+46UR8/frxlZ2ZmomXLloG9ZMmSSN/w0luYk04KH4q0MbcRJ8LcMpuWlobGjRtburTV1LXMeNppp4m6a3uwuVMuLy8vbufcwoULI31d6a1rm8La/Gy1bdvWsl0pyc8991xRd6WKd+2MfOaZZ4L2uHHjcNdddwX2W2+9Jfqav0dt4Dc/IZ7C4CfEUxj8hHgKg58QT2HwE+IpDH5CPIXBT4in1Pk6f3Hx9+n+MjIyLNvMnJMIKWOO6xikqwz2smXLLPuEE06wXpOOUZq/QyKKiopE/Y033hD18DVr3ry5pUvZcpRSYt+TJk0Sddfei9mzZwft3r17WzYgHwmWjvsC7r0bH3/8saj/5z//Cdrp6enW/gjXWrkr+1L4CHgY17FbM41YamqqZbuOeEt/70MOOUT0NeE3PyGewuAnxFMY/IR4CoOfEE9h8BPiKQx+QjyFwU+Ip9T5Or95hruwsNCyXWfHzXJLYaqqqkRfV3rtKVOmWPbQoUMxffr0wJ44cWKkr6s005tvvinqrhTW5trtjh074irVpKZG/xu+YsUKsW/XdevSpYuom3kSCgsLMWPGDEu/5pprIn03bdok9i35JoP5u23duhXvvvtuYA8aJNeWlariAPH5H8K49jD89re/DdpFRUUYPPj70heuCk6nnnqqqCcLv/kJ8RQGPyGewuAnxFMY/IR4CoOfEE9h8BPiKQx+QjzFuc6vlJoBoBLAF1rrrrHXJgAYCeDL2I+N11o/lcwbXn311UG7b9++lv3Pf/5T9P3JT34SqX3xxReir7RHAAA+/PBDyy4oKLBemzlzZqRvOFd9mBtuuEHUzTXeRIwaNSpop6enx53BHzFiRKRvo0aNxL6//vprUXftQTDPvefl5cVd55UrV0b6uvIg/Otf/xL1qVOnivqjjz4atHfv3m3l+V+/fr3o6zpTn5ubK+qFhYWi/tlnnwXtdu3aWbZ5tj8REyZMiNRcdRpMktnkczeAvwMI7zy4RWt9Y9LvRAhpUDhv+7XWLwOITsdCCPlRUpvtvWOUUr8FsBDAOK21fP9ICGlQpFRXVzt/SCnVFsATxjN/CYANAKoBXA2gTGs9PMJ3FIBRAKC1Pvy///1voHXs2BHLly8P7DZt2ojjSEtLi9Rc9e5cOdVatGgR915mDbyNGzdG+mZnZ4t9r1u3TtRdOf6aNWsWtFNSUhD+m4X3+pu49qhLdf6S0cvKyoJ2VlYWduzYYelSvb38/Hyxb9d1+fLLL0XdfMZv3749Pvroo8B2zYW4/qbfffedqOfk5Ii6OWeQn59v9bdlyxbRd9u2bZFaLOdiithBjH0K/mS1BFSXlJQExrx586wJI9eEn/QHcyX/DH8ow4QPkRQUFFgHT6QJP9chjv094Rc+jCNN+LVq1Urs2zXh5/pH9corrwzabdq0wSeffGLpF198caRv7969xb5/85vfiPoPmfCbPXu2dZ1dyUFdE34vvfSSqHftKodDz549g3bfvn3x6quvBrbrIJhUGDY24ZdU8O/TUp9SqswwTwHw3r70QwipP5JZ6nsAQAWAZkqpNQD+DKBCKdUNNbf9qwCccwDHSAg5ACR1278fqf73v/8dGL169bJqkZeXl4vO0m3e6tWrRV/XLeRrr71m2ePGjcNNN90U2NJ8w9atW8W+zbPbiXCtpZv7CA477DC88847li7lr5eeDwHgvvvuE/WmTZuKuvlYEb5mgLxm7dqb4TrXbj4OJaK0tDRoDx8+3Mo18Mwzz4i+ffr0EfXzzjtP1M25rUSYn+XbbrsNY8eODWypPgUQvyfFZN68ecCBvO0nhPz4YfAT4ikMfkI8hcFPiKcw+AnxFAY/IZ5S56m7b7755qA9efJkyz700ENFX+kIqGurqOt46JAhQyw7Ly/PWmILp6Q2cW3f7d69u6ib21ATMXr06KB9//33WzYAjBw5MtLXtfPRtdOtdevWoq61Dtrbt2+PK3U+bty4SF9pyQqwl+oS4bpuZir41NRUy77wwgtFX1fJd9dSoauEt7mVPTMz07I7deok+p5wwgminiz85ifEUxj8hHgKg58QT2HwE+IpDH5CPIXBT4inMPgJ8ZQ6X+e/9NJLg3ZpaallL1y4UPTdvHlzpLZ48WLR15Ve+/XXX7fso48+2npNOrbrShHmSoXl8jffe8+ePXFjeeihhyJ9pXTngJ2Ga18YOnRo0C4qKrJsALj11lsjfV0ZkAYOHCjq//jHP0TdLC+emppq7QXZtWuX6OsqXe7ag/Dyyy+LupnaOyUlxSqz7jri3blzZ1FPFn7zE+IpDH5CPIXBT4inMPgJ8RQGPyGewuAnxFMY/IR4Sp2v80+fPj1oX3XVVZb93nty7Q+zOkwYV2WZk08+WdRvvNEuOFxVVWWllu7bt2+krysPwZw5c0TdtQfBXCtv3bp13Nq5lALbrASTiMaNG4u6qzKNuea8Z8+euDJW0pn9I488UuxbqvYDuPcBPPzww0H7+OOPt2xX38OGDRN111q8K4fDOed8X+oiLy/Pqur0/PPP7/N7H3fccaKvCb/5CfEUBj8hnsLgJ8RTGPyEeAqDnxBPYfAT4ikMfkI8xbnOr5RqBeAeAKUA9gCYprWerJQqAjALQFsAqwAorfXXrv5ycnKCdmpqqmWbZYoT8fnnn0dqrrLGUv54ADjppJMsOycnB4cddlhgS+v8rj0Es2bNEvWuXbuK+oQJE4J2p06d8OCDD1p6eOwmKSlyteYWLVqI+g8pRZ2Wlha3b0Dam2GWa09Er169RN21v8I8z19cXGx9vlauXCn6Pvnkk6I+ePBgUU9Pl0PLLNt+0003WZ/PM844Q/SdP39+pHbZZZeJvibJfPNXARintT4YQG8Ao5VSnQFcCmC+1roDgPkxmxDyI8EZ/FrrdVrrxbH2ZgBLAbQAMBDAzNiPzQQw6EANkhCy//lBz/xKqbYAugNYAKBEa70OqPkHAkB0LS1CSIMjpbq6OqkfVErlA3gJwLVa67lKqW+01o0N/WutdZMEfqMAjAIArfXhq1atCrSysjKrzp2r3p4r153EV199JeoFBQWW3axZM2zYsCGpsa1YsULs25VHz5z3SMTatWuDdnl5uWUD8WM3kfIeAkDTpk1F3fXsauYTLCwsdJ6x+CFjM/PaJcLMg5cI87Odn59vnTtw5fBz/R5NmsR91C1ccy3m57Fly5ZYs2ZNYBcVFYm+X375ZaQWy4sov/neMSYT/EqpDABPAJintb459toyABVa63VKqTIAL2qt5YyMQPWoUaMCY/z48bjuuusCu3fv3qLzjh07nGON4t577xX18KTZiBEjcOeddwZ2Q5nwmzBhgmUD8oTfCy+8IPZtTjwlwnXwx5zw69+/P55++mlLlwLYNeHXqFEjUe/Xr5+om4lTjz76aLzyyiuB7SqueqAn/B544IGg/UMn/KZOnRqpxa5pUsHvvO1XSqUAuBPA0r2BH+MxAGfG2mcCeDSZNySENAySOdL7MwBnAFiilNr7z/x4ABMBaKXUCACrAcj/FMYwb5/T0tIs+4033hB9pTTT4aOkYZRSot68eXPLzsrKQvv27QP7o48+ivQdPny42Ld0Ww4AixYtEvXTTz89aDdt2tSyAeCOO+6I9D311FPFvqWy54C7xLfLX3pUy87OFn1dqb3feecdUTcfSXr06IG33norsD/++GPR1/VYcNFFF4n6+PHjRd18FMzKyrJsV3nwbt26iXqyOINfa/0qom8jjt8voyCE1Dnc4UeIpzD4CfEUBj8hnsLgJ8RTGPyEeAqDnxBPqfPU3Z06dQra2dnZlr1z507RV9oG27NnT9E3vCsuTHib61FHHWWlUJbW8j/77DOxb1e5ZnMbsYuDDjoobu29T58+kT//5ptviv25dCktOGCXXM/NzY1bgzZ3AIY58cQTxb7D+xnCaK1FfdKkSVZfZhrzdu3aib6urce33HKLqLv+puYW3V27dlm2a4/A448/LurJwm9+QjyFwU+IpzD4CfEUBj8hnsLgJ8RTGPyEeAqDnxBPqfN1fnPdeNeuXZZdUVEh+kpn6i+44ALR17WuG95DEE4rLp1rl/IMAO6z48uWLRP13//+90G7sLAwLnOPeU49jOtcuiv99aBBcl7WIUOGBO1Zs2ZZNuAuwy1x4YUXirqrlLWZljwjI8Oyc3NzRV9XdiVXCrFHHnlE1A8//HBrLGaaeFfKuR49eoh6svCbnxBPYfAT4ikMfkI8hcFPiKcw+AnxFAY/IZ7C4CfEU+p8nT8jIyNop6SkWPb9998v+krn/adMmSL6unKhm5WEgJp89Ob6ulQW+ZNPPhH7zsvLE3Wp/BJgr9VXV1fHrd1v2bIl0rd79+5J950IVy4Cs7RUenp6XKmpjh07RvouX75c7NtV9cb87CTC3H+RkZFh2S1bthR9XfsAXKXN27RpI+pz5swJ2pWVlZbdtm1b0Vcq/+aqJGTCb35CPIXBT4inMPgJ8RQGPyGewuAnxFMY/IR4CoOfEE9xrvMrpVoBuAdAKYA9AKZprScrpSYAGAlg7yL1eK31U67+zLPtO3futOzS0lLR95BDDonUXGfid+zYIerh3PslJSXWa9JafHhtO4zrfHZmZqaom+e3c3Nz485zS3Xu586dK/Y9ZswYUc/KyhL1goKCoN2kSZO4dealS5dG+rZq1Urse9WqVaJeVVUl6uZ6eWpqqnWdKisrRd+77rpL1Pv37y/qe/bsEfXy8vKgnZGRYdkdOnQQfV2/d7Iks8mnCsA4rfVipVQjAIuUUs/FtFu01jful5EQQuoUZ/BrrdcBWBdrb1ZKLQUgb28ihDR4Uqqrq5P+YaVUWwAvA+gK4A8AzgKwCcBC1NwdfJ3AZxSAUQCgtT7c3ApbWlqKzz//PLBd2zWlcl0uXOWXmjRpYtm5ubnYunVrUv6pqfLUies2zTW29u3bB+309PS4/rZt2xbp+80334h9FxcXi3pKSoqof/vtt0G7qKgo7hFn+/btkb6u7buu8m2uz675yNK8eXPr0S1cni3Mxo0bRb158+aivn79elE3H0NbtmyJNWvWBLbrcy793rFty/IfLUbSwa+UygfwEoBrtdZzlVIlADYAqAZwNYAyrXV0Qbsaqs8999zAuOyyy3D99dcHdm2e+V0B+OKLL4r6r3/9a8vu0aMHFi9eHNivvPJKpK/0zA24n/lfeOEFUZ89e3bQLi4ujquf9/7770f6Huhn/qeffjpoDxkyBLNmzbJ06Znf9Q/P6tWrRf2HPPOfe+65mDp1amCfddZZoq/rmd/8HCdi8uTJom7mo/zrX/+Kiy++OLC7dOki+kq/dyyekgr+pA72KKUyAMwBcJ/Wei4AaK3XG/p0ANEZLgkhDQ7nUp9SKgXAnQCWaq1vNl43U9aeAuC9/T88QsiBIplv/p8BOAPAEqXU3nrL4wEMU0p1Q81t/yoA5yTzhosWLQraW7ZssWzpth4A1q1bF6m5jkG6+g4vK3Xp0sW51LQXc24gEa40z+FHjjC33npr0D7//PMtGwCWLFkS6esqg+0qc+363cw5gZ07d+LTTz+1dOmRRjqaCriPza5cuVLUzWfnXbt2Wc/hr7/+uuhrPoMn4vLLLxf1oUOHirp5656VlWUdAZbmSQB3SfhkSWa2/1UkfoZwrukTQhou3OFHiKcw+AnxFAY/IZ7C4CfEUxj8hHgKg58QT6nz1N3jx48P2mVlZZYtbaEFgLS0tEjNtRfbtY01nNp79+7d2LRpU2BLWyprsz8BQNx23TDm8dGCgoK446Thkt0mt99+u9i3a7163rx5om4ey0103FhKgd2vXz+xb9d1c6XHHjZsWNAuLS3FJZdcEthjx44VffPz80V90qRJoj5x4sQf1L95zsGVLt0s710b+M1PiKcw+AnxFAY/IZ7C4CfEUxj8hHgKg58QT2HwE+IpPyiH336gTt+MEE+M7h7mAAAC0ElEQVRJKo1XXX/zp5j/KaUWhV9rKP811LE11HFxbA1qbEnB235CPIXBT4in1HfwT6vn95doqGNrqOMCOLZ9pV7GVtcTfoSQBkJ9f/MTQuqJOj/SCwBKqZMATAaQBuAOrbV8/rEOUUqtArAZwG4AVVrrnvU4lhkAKgF8obXuGnutCMAsAG1RkzJdJSqTVk9jm4B9qNx8AMYWVVm6Xq/d/q54XVvq/JtfKZUGYAqA/gA6oyb/f+e6HoeDY7XW3eoz8GPcDSB8WP9SAPO11h0AzI/Z9cHdiB8bUFO5uVvsv/pK7763svTBAHoDGB37jNX3tYsaF1AP160+bvt7AVihtV6ptd4J4EEAA+thHA0erfXLAMKF/gYCmBlrzwQwqE4HFSNibA0CrfU6rfXiWHszgL2Vpev12gnjqhfqI/hbADDLuqxBwyr5XQ3gWaXUoliF4YZGSaxs+t7y6XK1y7pnjFLqXaXUDKVUE/ePH1hilaW7A1iABnTtQuMC6uG61UfwJ9qB1JCWHH6mte6BmseS0Uqpn9f3gH5E3A6gPYBuANYBuKk+BxOrLD0HwAVa602un68rEoyrXq5bfQT/GgCtDLslgLX1MI6EaK3Xxv7/BYCHUfOY0pBYv7dIauz/cgLAOkRrvV5rvVtrvQfAdNTjtUtUWRoN4NpFVbyuj+tWH8H/NoAOSql2SqlMAEMBPFYP44hDKZWnlGq0tw3gRDS86sOPATgz1j4TwKP1OBaLhlK5OaqyNOr52jW0itf1sslHKTUAwN9Qs9Q3Q2t9bZ0PIgFKqZ+g5tseqFkGvb8+x6aUegBABYBmANYD+DOARwBoAK0BrAYwWGtd5xNvEWOrQM2ta1C5ee8zdh2PrS+AVwAsQc2SGlBTWXoB6vHaCeMahnq4btzhR4incIcfIZ7C4CfEUxj8hHgKg58QT2HwE+IpDH5CPIXBT4inMPgJ8ZT/A2Ti/M0B/lZPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im=np.reshape((train_x[1]+train_x[0])/2,[1,28,28,1])\n",
    "im = safe_images[0]\n",
    "img = np.reshape(im,[28,28])\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_images = np.reshape(np.random.normal(0,1,[9200*28*28]),[9200,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
