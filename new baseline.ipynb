{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Training X shape: (60000, 784)\n",
      "Testing X shape: (10000, 784)\n",
      "Validation X shape: (0, 784)\n",
      "\n",
      "Training Y shape: (60000, 10)\n",
      "Testing Y shape: (10000, 10)\n",
      "Validation Y shape: (0, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data/mnist', validation_size=0, one_hot=True)\n",
    "test_len = mnist.test.images.shape[0]\n",
    "validation_len = int(test_len * 0)\n",
    "num_label=10\n",
    "train_x = mnist.train.images\n",
    "test_x = mnist.test.images[validation_len : test_len, :]\n",
    "validation_x = mnist.test.images[ : validation_len, :]\n",
    "\n",
    "train_y = mnist.train.labels\n",
    "test_y = mnist.test.labels[validation_len : test_len]\n",
    "validation_y = mnist.test.labels[ : validation_len]\n",
    "\n",
    "print(\"\\nTraining X shape: \" + str(train_x.shape))\n",
    "print(\"Testing X shape: \" + str(test_x.shape))\n",
    "print(\"Validation X shape: \" + str(validation_x.shape))\n",
    "\n",
    "print(\"\\nTraining Y shape: \" + str(train_y.shape))\n",
    "print(\"Testing Y shape: \" + str(test_y.shape))\n",
    "print(\"Validation Y shape: \" + str(validation_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, ?)\n",
      "(?,)\n",
      "(?,)\n",
      "()\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From /Users/senqicao/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./baseline2/classification_mnist39/model.ckpt\n",
      "time: 0 27.87461519241333 train accuracy test accuracy 0.9846 0.7907916\n",
      "time: 100 211.06593418121338 train accuracy test accuracy 0.9816 0.99977434\n",
      "time: 200 395.04737615585327 train accuracy test accuracy 0.9862 0.9992749\n",
      "time: 300 576.8495581150055 train accuracy test accuracy 0.9893 0.99641556\n",
      "time: 400 760.693213224411 train accuracy test accuracy 0.9884 0.9982697\n",
      "time: 500 942.4445991516113 train accuracy test accuracy 0.9876 0.99115413\n",
      "time: 600 1124.9078052043915 train accuracy test accuracy 0.986 0.9968909\n",
      "time: 700 1307.867832183838 train accuracy test accuracy 0.9879 0.99993813\n",
      "time: 800 1488.715737104416 train accuracy test accuracy 0.987 0.9995757\n",
      "time: 900 1670.9868264198303 train accuracy test accuracy 0.986 0.9976024\n",
      "time: 1000 1851.173457145691 train accuracy test accuracy 0.9871 0.99912685\n",
      "time: 1100 2033.596740245819 train accuracy test accuracy 0.9887 0.99995303\n",
      "time: 1200 2219.5775051116943 train accuracy test accuracy 0.985 0.9999855\n",
      "time: 1300 2400.2394313812256 train accuracy test accuracy 0.9887 0.9999987\n",
      "time: 1400 2582.3833091259003 train accuracy test accuracy 0.9867 0.99994415\n",
      "time: 1500 2765.642873287201 train accuracy test accuracy 0.9874 0.98853\n",
      "time: 1600 2951.649593114853 train accuracy test accuracy 0.989 0.9441827\n",
      "time: 1700 3133.6184163093567 train accuracy test accuracy 0.9853 0.99602294\n",
      "time: 1800 3314.7780170440674 train accuracy test accuracy 0.9878 0.99982387\n",
      "time: 1900 3497.1749811172485 train accuracy test accuracy 0.9886 0.985475\n",
      "time: 2000 3679.219669342041 train accuracy test accuracy 0.9858 0.9930888\n",
      "time: 2100 3867.7395293712616 train accuracy test accuracy 0.9889 0.9775798\n",
      "time: 2200 4049.825841188431 train accuracy test accuracy 0.9872 0.9772682\n",
      "time: 2300 4229.497235298157 train accuracy test accuracy 0.9881 0.00027308526\n",
      "time: 2400 4411.501980304718 train accuracy test accuracy 0.9867 0.9998726\n",
      "time: 2500 4591.682170152664 train accuracy test accuracy 0.989 0.99910206\n",
      "time: 2600 4783.963448047638 train accuracy test accuracy 0.9867 0.99669856\n",
      "time: 2700 4965.496783256531 train accuracy test accuracy 0.988 0.9946202\n",
      "time: 2800 5146.392005205154 train accuracy test accuracy 0.9875 0.9978804\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "n_intergal_sample = 30\n",
    "D=7*7*64\n",
    "h1=512\n",
    "D2=10\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# variables\n",
    "X = tf.placeholder(tf.float32, shape = [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "w_conv1 = tf.get_variable('w_conv1', [5,5, 1,32], initializer = tf.contrib.layers.xavier_initializer())\n",
    "#b_conv1 = bias_variable('b_conv1', [first_conv[3]])\n",
    "w_conv2 = tf.get_variable('w_conv2', [5,5,32,64], initializer = tf.contrib.layers.xavier_initializer())\n",
    "#b_conv2 =bias_variable('b_conv2', [second_conv[3]])\n",
    "\n",
    "w_fc1 = tf.get_variable('w_fc1', [7*7*64, h1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "#b_fc1 = tf.get_variable('b_fc1', [1,512])\n",
    "b_fc1 = tf.get_variable('b_fc1', [1,h1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "w_fc2 = tf.get_variable('w_fc2', [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b_fc2 = tf.get_variable('b_fc2', [1,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "\n",
    "eps1 = tf.random_normal(shape=[n_intergal_sample,D,h1], mean=0.0, stddev=1,dtype=tf.float32)\n",
    "eps2 = tf.random_normal(shape=[n_intergal_sample,1,h1], mean=0.0, stddev=1,dtype=tf.float32)\n",
    "eps3 = tf.random_normal(shape=[n_intergal_sample,h1,D2], mean=0.0, stddev=1,dtype=tf.float32)\n",
    "eps4 = tf.random_normal(shape=[n_intergal_sample,1,D2], mean=0.0, stddev=1,dtype=tf.float32)\n",
    "\n",
    "eps11 = tf.reshape(eps1,[n_intergal_sample,D*h1])\n",
    "eps22 = tf.reshape(eps2,[n_intergal_sample,1*h1])\n",
    "eps33 = tf.reshape(eps3,[n_intergal_sample,h1*D2])\n",
    "eps44 = tf.reshape(eps4,[n_intergal_sample,1*D2])\n",
    "\n",
    "input_latent = tf.concat([eps11,eps22,eps33,eps44],1)\n",
    "hidden1 = tf.layers.dense(input_latent, 15, activation=tf.nn.relu)\n",
    "#hidden2 = tf.layers.dense(hidden1, 5, activation=tf.nn.relu)\n",
    "#hidden3 = tf.layers.dense(hidden2, 30, activation=tf.nn.relu)\n",
    "output_latent = tf.layers.dense(hidden1,(D*h1 + 1*h1+ h1*D2 + 1*D2), activation=None)\n",
    "\n",
    "w0 = tf.reshape(output_latent[:,0:D*h1],[n_intergal_sample,D,h1])\n",
    "b0 = tf.reshape(output_latent[:,D*h1:D*h1+1*h1],[n_intergal_sample,1,h1])\n",
    "w1 = tf.reshape(output_latent[:,D*h1+1*h1:D*h1+1*h1+h1*D2],[n_intergal_sample,h1,D2])\n",
    "b1 = tf.reshape(output_latent[:,D*h1+1*h1+h1*D2:D*h1+1*h1+h1*D2+1*D2],[n_intergal_sample,1,D2])\n",
    "\n",
    "# network\n",
    "b=True\n",
    "con1 = tf.nn.conv2d(X, w_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv1 = tf.nn.relu(tf.layers.batch_normalization(con1, training=b))\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "con2 = tf.nn.conv2d(h_pool1, w_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_conv2 = tf.nn.relu(tf.layers.batch_normalization(con2, training=b))\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "h_pool2_flat = tf.layers.flatten(h_pool2)\n",
    "h_pool2_flat1 = tf.stack([h_pool2_flat]*n_intergal_sample)\n",
    "\n",
    "h = tf.nn.relu(tf.matmul(h_pool2_flat1, w0) + b0)\n",
    "logits = tf.matmul(h, w1) + b1\n",
    "output0 = tf.nn.softmax(logits)\n",
    "\n",
    "probs = tf.reduce_sum(output0*Y,2)\n",
    "print(probs.shape)\n",
    "prob=tf.reduce_mean(probs,0)\n",
    "print(prob.shape)\n",
    "log_prob = tf.log(prob)\n",
    "print(log_prob.shape)\n",
    "p = tf.reduce_mean(log_prob)\n",
    "print(p.shape)\n",
    "\n",
    "output = tf.reduce_mean(output0,0)\n",
    "print(output.shape)\n",
    "#output = tf.nn.softmax(logits)\n",
    "\n",
    "likelihood = tf.tensordot(output[0],Y[0],1)\n",
    "#cross_ent = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(output), reduction_indices=[1]))\n",
    "\n",
    "#cross_ent=tf.nn.softmax_cross_entropy_with_logits(logits = output, labels=Y)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "# training\n",
    "a = 0.00001\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_step = tf.train.AdamOptimizer(a).minimize(-p)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model_id=40\n",
    "    save_path = saver.restore(sess, \"./baseline2/classification_mnist39/model.ckpt\")\n",
    "    for i in range(60000*100):\n",
    "        batch = mnist.train.next_batch(M)\n",
    "        x_batch = np.reshape(batch[0],[M, 28, 28, 1])\n",
    "        y_batch = batch[1]\n",
    "        \n",
    "        if i%100==0:\n",
    "            b=False\n",
    "            #accu = sess.run(accuracy,{X: np.reshape(mnist.train.images,[55000,28,28,1]), Y: mnist.train.labels})\n",
    "            test_error = sess.run(accuracy, {X:np.reshape(mnist.test.images,[10000,28,28,1]), Y:mnist.test.labels})\n",
    "            like = sess.run(likelihood,{X: x_batch, Y: y_batch})\n",
    "\n",
    "            print (\"time:\",i, time.time() - start_time, \"train accuracy\", \"test accuracy\", test_error, like)\n",
    "        if i < 1000:\n",
    "            a = 0.00001\n",
    "            a = 0.000001\n",
    "            b = True\n",
    "            sess.run(train_step,{X: x_batch, Y: y_batch})\n",
    "        elif i < 10000:\n",
    "            a = 0.000005\n",
    "            a = 0.000001\n",
    "            b = True\n",
    "            sess.run(train_step,{X: x_batch, Y: y_batch})\n",
    "        elif i < 60000:\n",
    "            a = 0.000001\n",
    "            b = True\n",
    "            sess.run(train_step,{X: x_batch, Y: y_batch})\n",
    "        else:\n",
    "            a = 0.0000003\n",
    "            b = True\n",
    "            sess.run(train_step,{X: x_batch, Y: y_batch})\n",
    "        \n",
    "        \n",
    "        if i%500==0:\n",
    "            save_path = saver.save(sess, \"./baseline2/classification_mnist%s/model.ckpt\" % model_id)\n",
    "            model_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314710"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D*h1 + 1*h1+ h1*D2 + 1*D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
